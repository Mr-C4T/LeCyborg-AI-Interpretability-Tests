{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing SAE Feature Activations from Parquet Files\n",
    "\n",
    "This notebook loads and analyzes feature activations from parquet files that were generated by the `record_feature_activations.py` script. It processes the data in a memory-efficient way by loading files in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "import gc\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up the analysis parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AnalysisConfig:\n",
    "    \"\"\"Configuration for feature analysis\"\"\"\n",
    "    # Analysis parameters\n",
    "    top_k_global: int = 50  # Top K frames globally for each feature\n",
    "    top_s_per_episode: int = 3  # Top S frames per episode for each feature\n",
    "    min_variance_threshold: float = 0.01  # Ignore low-variance features\n",
    "    \n",
    "    # Feature ranking criteria\n",
    "    ranking_metric: str = 'variance'  # 'variance', 'range', 'sparsity', 'composite'\n",
    "    sparsity_threshold: float = 0.1  # Threshold for considering a feature \"active\"\n",
    "    \n",
    "    # Data processing\n",
    "    batch_size: int = 1000  # Number of episodes to process at once\n",
    "    max_features_to_analyze: int = 100  # Max features to analyze in detail\n",
    "    \n",
    "    # Output settings\n",
    "    output_dir: str = \"./feature_analysis_results\"\n",
    "    create_plots: bool = True\n",
    "    save_detailed_examples: bool = True\n",
    "\n",
    "# Create config\n",
    "config = AnalysisConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Statistics Class\n",
    "\n",
    "This class tracks statistics for each feature as we process the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureStatistics:\n",
    "    \"\"\"Statistics for a single feature\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_idx: int):\n",
    "        self.feature_idx = feature_idx\n",
    "        self.values = []\n",
    "        self.frame_indices = []\n",
    "        self.episode_indices = []\n",
    "        self.dataset_indices = []\n",
    "        \n",
    "        # Computed statistics\n",
    "        self.mean = 0.0\n",
    "        self.std = 0.0\n",
    "        self.variance = 0.0\n",
    "        self.min_val = 0.0\n",
    "        self.max_val = 0.0\n",
    "        self.range_val = 0.0\n",
    "        self.range_75_95 = 0.0\n",
    "        self.percentiles = {}\n",
    "        self.sparsity = 0.0  # Fraction of values below threshold\n",
    "        self.activity_rate = 0.0  # Fraction of values above threshold\n",
    "        \n",
    "        # Rankings\n",
    "        self.variance_rank = 0\n",
    "        self.range_rank = 0\n",
    "        self.sparsity_rank = 0\n",
    "        self.composite_rank = 0\n",
    "    \n",
    "    def add_values(self, values: np.ndarray, frame_indices: List[int], episode_indices: List[int], dataset_indices: List[int]):\n",
    "        \"\"\"Add new values to the statistics\"\"\"\n",
    "        self.values.extend(values.tolist())\n",
    "        self.frame_indices.extend(frame_indices)\n",
    "        self.episode_indices.extend(episode_indices)\n",
    "        self.dataset_indices.extend(dataset_indices)\n",
    "    \n",
    "    def compute_statistics(self, sparsity_threshold: float = 0.1):\n",
    "        \"\"\"Compute final statistics from collected values\"\"\"\n",
    "        if not self.values:\n",
    "            return\n",
    "        \n",
    "        values_array = np.array(self.values)\n",
    "        \n",
    "        self.mean = float(values_array.mean())\n",
    "        self.std = float(values_array.std())\n",
    "        self.variance = float(values_array.var())\n",
    "        self.min_val = float(values_array.min())\n",
    "        self.max_val = float(values_array.max())\n",
    "        self.range_val = self.max_val - self.min_val\n",
    "        \n",
    "        # Percentiles\n",
    "        percentile_points = [1, 5, 10, 25, 50, 75, 90, 95, 99]\n",
    "        self.percentiles = {\n",
    "            p: float(np.percentile(values_array, p)) \n",
    "            for p in percentile_points\n",
    "        }\n",
    "        \n",
    "        self.range_75_95 = self.percentiles[95] - self.percentiles[75]\n",
    "        # Sparsity (fraction of values below threshold)\n",
    "        self.sparsity = float((np.abs(values_array) < sparsity_threshold).mean())\n",
    "        self.activity_rate = 1.0 - self.sparsity\n",
    "    \n",
    "    def get_ranking_score(self, metric: str) -> float:\n",
    "        \"\"\"Get score for ranking features\"\"\"\n",
    "        if metric == 'variance':\n",
    "            # return self.variance\n",
    "            return self.variance\n",
    "        elif metric == 'range':\n",
    "            return self.range_val\n",
    "        elif metric == 'sparsity':\n",
    "            # Higher activity rate (lower sparsity) is better\n",
    "            return self.activity_rate\n",
    "        elif metric == 'composite':\n",
    "            # Composite score: variance * range * activity_rate\n",
    "            return self.variance * self.range_val * self.activity_rate\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown ranking metric: {metric}\")\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary for saving\"\"\"\n",
    "        return {\n",
    "            'feature_idx': self.feature_idx,\n",
    "            'mean': self.mean,\n",
    "            'std': self.std,\n",
    "            'variance': self.variance,\n",
    "            'min': self.min_val,\n",
    "            'max': self.max_val,\n",
    "            'range': self.range_val,\n",
    "            'percentiles': self.percentiles,\n",
    "            'sparsity': self.sparsity,\n",
    "            'activity_rate': self.activity_rate,\n",
    "            'num_samples': len(self.values),\n",
    "            'rankings': {\n",
    "                'variance_rank': self.variance_rank,\n",
    "                'range_rank': self.range_rank,\n",
    "                'sparsity_rank': self.sparsity_rank,\n",
    "                'composite_rank': self.composite_rank\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Parquet Files\n",
    "\n",
    "Now let's process the parquet files in batches to compute feature statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_frame_analysis(dataset_id: int, output_dir: str) -> Dict:\n",
    "    \"\"\"Load frame analysis for a specific dataset\"\"\"\n",
    "    frame_analysis_dir = Path(output_dir) / \"frame_analysis\"\n",
    "    file_path = frame_analysis_dir / f\"dataset_{dataset_id:03d}_frame_analysis.json\"\n",
    "    \n",
    "    if not file_path.exists():\n",
    "        raise FileNotFoundError(f\"Frame analysis file not found: {file_path}\")\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def get_most_active_features_in_episode(dataset_id: int, episode_id: int, output_dir: str, top_k: int = 10) -> List[int]:\n",
    "    \"\"\"Get the most frequently highly-active features in a specific episode\"\"\"\n",
    "    data = load_dataset_frame_analysis(dataset_id, output_dir)\n",
    "    \n",
    "    if str(episode_id) not in data:\n",
    "        return []\n",
    "    \n",
    "    episode_data = data[str(episode_id)]\n",
    "    feature_counts = {}\n",
    "    \n",
    "    # Count how many times each feature appears as highly active\n",
    "    for frame_idx, features in episode_data.items():\n",
    "        for feature_info in features:\n",
    "            feature_idx = feature_info['feature_idx']\n",
    "            if feature_idx not in feature_counts:\n",
    "                feature_counts[feature_idx] = 0\n",
    "            feature_counts[feature_idx] += 1\n",
    "    \n",
    "    # Sort by count and return top_k\n",
    "    sorted_features = sorted(feature_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [feature_idx for feature_idx, count in sorted_features[:top_k]]\n",
    "\n",
    "def get_frame_activation_summary(dataset_id: int, episode_id: int, frame_idx: int, output_dir: str) -> List[Dict]:\n",
    "    \"\"\"Get detailed activation summary for a specific frame\"\"\"\n",
    "    data = load_dataset_frame_analysis(dataset_id, output_dir)\n",
    "    \n",
    "    if str(episode_id) not in data:\n",
    "        return []\n",
    "    \n",
    "    episode_data = data[str(episode_id)]\n",
    "    if str(frame_idx) not in episode_data:\n",
    "        return []\n",
    "    \n",
    "    return episode_data[str(frame_idx)]\n",
    "\n",
    "def analyze_feature_temporal_patterns(dataset_id: int, episode_id: int, feature_idx: int, output_dir: str) -> List[int]:\n",
    "    \"\"\"Get all frame indices where a specific feature was highly active in an episode\"\"\"\n",
    "    data = load_dataset_frame_analysis(dataset_id, output_dir)\n",
    "    \n",
    "    if str(episode_id) not in data:\n",
    "        return []\n",
    "    \n",
    "    episode_data = data[str(episode_id)]\n",
    "    active_frames = []\n",
    "    \n",
    "    for frame_idx, features in episode_data.items():\n",
    "        for feature_info in features:\n",
    "            if feature_info['feature_idx'] == feature_idx:\n",
    "                active_frames.append(int(frame_idx))\n",
    "                break\n",
    "    \n",
    "    return sorted(active_frames)\n",
    "\n",
    "# Example usage functions\n",
    "def print_episode_summary(dataset_id: int, episode_id: int, output_dir: str):\n",
    "    \"\"\"Print a summary of feature activations for an episode\"\"\"\n",
    "    print(f\"Episode Summary - Dataset {dataset_id}, Episode {episode_id}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        data = load_dataset_frame_analysis(dataset_id, output_dir)\n",
    "        \n",
    "        if str(episode_id) not in data:\n",
    "            print(\"Episode not found in data\")\n",
    "            return\n",
    "        \n",
    "        episode_data = data[str(episode_id)]\n",
    "        total_frames = len(episode_data)\n",
    "        \n",
    "        # Count unique features across all frames\n",
    "        all_features = set()\n",
    "        frame_counts = []\n",
    "        \n",
    "        for frame_idx, features in episode_data.items():\n",
    "            frame_counts.append(len(features))\n",
    "            for feature_info in features:\n",
    "                all_features.add(feature_info['feature_idx'])\n",
    "        \n",
    "        print(f\"Total frames: {total_frames}\")\n",
    "        print(f\"Unique highly-active features: {len(all_features)}\")\n",
    "        print(f\"Average highly-active features per frame: {np.mean(frame_counts):.1f}\")\n",
    "        print(f\"Max highly-active features in a frame: {max(frame_counts) if frame_counts else 0}\")\n",
    "        \n",
    "        # Most frequent features\n",
    "        most_active = get_most_active_features_in_episode(dataset_id, episode_id, output_dir, top_k=5)\n",
    "        print(f\"\\nMost frequently active features:\")\n",
    "        for i, feature_idx in enumerate(most_active):\n",
    "            active_frames = analyze_feature_temporal_patterns(dataset_id, episode_id, feature_idx, output_dir)\n",
    "            print(f\"  {i+1}. Feature {feature_idx}: active in {len(active_frames)} frames\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Example: uncomment to analyze a specific episode after running the frame analysis\n",
    "# print_episode_summary(dataset_id=0, episode_id=0, output_dir=config.output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_parquet_files(parquet_dir: str, config: AnalysisConfig) -> Tuple[Dict[int, FeatureStatistics], List[int]]:\n",
    "    \"\"\"Process parquet files in batches to compute feature statistics\"\"\"\n",
    "    parquet_dir = Path(parquet_dir)\n",
    "    parquet_files = sorted(list(parquet_dir.glob(\"*.parquet\")))\n",
    "    \n",
    "    if not parquet_files:\n",
    "        raise ValueError(f\"No parquet files found in {parquet_dir}\")\n",
    "    \n",
    "    logging.info(f\"Found {len(parquet_files)} parquet files to process\")\n",
    "    \n",
    "    # Initialize feature statistics\n",
    "    feature_stats = {}\n",
    "    \n",
    "    # Process files in batches\n",
    "    for i in tqdm(range(0, len(parquet_files), config.batch_size), desc=\"Processing batches\"):\n",
    "        batch_files = parquet_files[i:i + config.batch_size]\n",
    "        \n",
    "        # Process each file in the batch\n",
    "        for file_path in tqdm(batch_files, desc=\"Processing files\", leave=False):\n",
    "            # Read parquet file\n",
    "            df = pd.read_parquet(file_path)\n",
    "            \n",
    "            # Group by feature index\n",
    "            for feature_idx, group in df.groupby('feature_index'):\n",
    "                if feature_idx not in feature_stats:\n",
    "                    feature_stats[feature_idx] = FeatureStatistics(feature_idx)\n",
    "                \n",
    "                # Add values to statistics\n",
    "                feature_stats[feature_idx].add_values(\n",
    "                    group['activation'].values,\n",
    "                    group['frame_index'].tolist(),\n",
    "                    group['episode_id'].tolist(),\n",
    "                    group['dataset_id'].tolist()\n",
    "                )\n",
    "        \n",
    "        # Force garbage collection after each batch\n",
    "        import gc\n",
    "        gc.collect()\n",
    "    \n",
    "    # Compute final statistics\n",
    "    logging.info(\"Computing final statistics...\")\n",
    "    for stats in feature_stats.values():\n",
    "        stats.compute_statistics(config.sparsity_threshold)\n",
    "    \n",
    "    # Rank features\n",
    "    ranked_features = rank_features(feature_stats, config)\n",
    "    \n",
    "    return feature_stats, ranked_features\n",
    "\n",
    "def rank_features(feature_stats: Dict[int, FeatureStatistics], config: AnalysisConfig) -> List[int]:\n",
    "    \"\"\"Rank features by importance\"\"\"\n",
    "    # Filter features by variance threshold\n",
    "    valid_features = [\n",
    "        feature_idx for feature_idx, stats in feature_stats.items()\n",
    "        if stats.variance >= config.min_variance_threshold\n",
    "    ]\n",
    "    \n",
    "    # Rank by chosen metric\n",
    "    feature_scores = [\n",
    "        (feature_idx, feature_stats[feature_idx].get_ranking_score(config.ranking_metric))\n",
    "        for feature_idx in valid_features\n",
    "    ]\n",
    "    \n",
    "    # Sort by score (highest first)\n",
    "    feature_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    ranked_features = [feature_idx for feature_idx, score in feature_scores]\n",
    "    \n",
    "    # Update ranking information in statistics\n",
    "    for rank, feature_idx in enumerate(ranked_features):\n",
    "        feature_stats[feature_idx].variance_rank = rank\n",
    "    \n",
    "    logging.info(f\"Ranked {len(ranked_features)} features by {config.ranking_metric}\")\n",
    "    return ranked_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_batches(total_features: int, num_batches: int = 20) -> List[Tuple[int, int]]:\n",
    "    \"\"\"Split features into batches of roughly equal size\"\"\"\n",
    "    batch_size = total_features // num_batches\n",
    "    batches = []\n",
    "    for i in range(num_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size if i < num_batches - 1 else total_features\n",
    "        batches.append((start, end))\n",
    "    return batches\n",
    "\n",
    "def process_feature_batch(parquet_dir: str, feature_batch: Tuple[int, int], config: AnalysisConfig) -> Tuple[Dict[int, FeatureStatistics], List[int]]:\n",
    "    \"\"\"Process a single batch of features\"\"\"\n",
    "    parquet_dir = Path(parquet_dir)\n",
    "    parquet_files = sorted(list(parquet_dir.glob(\"*.parquet\")))\n",
    "    \n",
    "    if not parquet_files:\n",
    "        raise ValueError(f\"No parquet files found in {parquet_dir}\")\n",
    "    \n",
    "    start_feature, end_feature = feature_batch\n",
    "    logging.info(f\"Processing features {start_feature} to {end_feature}\")\n",
    "    \n",
    "    # Initialize feature statistics for this batch\n",
    "    feature_stats = {}\n",
    "    \n",
    "    # Process files in batches\n",
    "    for i in tqdm(range(0, len(parquet_files), config.batch_size), desc=\"Processing batches\"):\n",
    "        batch_files = parquet_files[i:i + config.batch_size]\n",
    "        \n",
    "        # Process each file in the batch\n",
    "        for file_path in tqdm(batch_files, desc=\"Processing files\", leave=False):\n",
    "            # Read parquet file\n",
    "            df = pd.read_parquet(file_path)\n",
    "            \n",
    "            # Filter for features in this batch\n",
    "            df = df[df['feature_index'].between(start_feature, end_feature - 1)]\n",
    "            \n",
    "            # Group by feature index\n",
    "            for feature_idx, group in df.groupby('feature_index'):\n",
    "                if feature_idx not in feature_stats:\n",
    "                    feature_stats[feature_idx] = FeatureStatistics(feature_idx)\n",
    "                \n",
    "                # Add values to statistics\n",
    "                feature_stats[feature_idx].add_values(\n",
    "                    group['activation'].values,\n",
    "                    group['frame_index'].tolist(),\n",
    "                    group['episode_id'].tolist(),\n",
    "                    group['dataset_id'].tolist(),\n",
    "                )\n",
    "        \n",
    "        # Force garbage collection after each batch\n",
    "        import gc\n",
    "        gc.collect()\n",
    "    \n",
    "    # Compute final statistics\n",
    "    logging.info(\"Computing final statistics...\")\n",
    "    for stats in feature_stats.values():\n",
    "        stats.compute_statistics(config.sparsity_threshold)\n",
    "    \n",
    "    # Rank features in this batch\n",
    "    ranked_features = rank_features(feature_stats, config)\n",
    "    \n",
    "    return feature_stats, ranked_features\n",
    "\n",
    "def find_top_examples_for_batch(parquet_dir: str, feature_batch: Tuple[int, int], \n",
    "                              ranked_features: List[int], config: AnalysisConfig) -> Dict[int, Dict[str, List]]:\n",
    "    \"\"\"Find top examples for a batch of features\"\"\"\n",
    "    logging.info(\"Finding top examples from saved episode data...\")\n",
    "    \n",
    "    parquet_dir = Path(parquet_dir)\n",
    "    parquet_files = sorted(list(parquet_dir.glob(\"*.parquet\")))\n",
    "    \n",
    "    start_feature, end_feature = feature_batch\n",
    "    top_examples = {feature_idx: {'global_high': [], 'global_low': [], 'episode_examples': {}} \n",
    "                   for feature_idx in ranked_features[:config.max_features_to_analyze]}\n",
    "    \n",
    "    # Process files in batches\n",
    "    for i in tqdm(range(0, len(parquet_files), config.batch_size), desc=\"Processing batches\"):\n",
    "        batch_files = parquet_files[i:i + config.batch_size]\n",
    "        \n",
    "        for file_path in tqdm(batch_files, desc=\"Processing files\", leave=False):\n",
    "            # Load episode data\n",
    "            episode_df = pd.read_parquet(file_path)\n",
    "            episode_id = episode_df['episode_id'].iloc[0] if len(episode_df) > 0 else None\n",
    "            dataset_id = episode_df['dataset_id'].iloc[0] if len(episode_df) > 0 else None\n",
    "\n",
    "            # Filter for features in this batch\n",
    "            episode_df = episode_df[episode_df['feature_index'].between(start_feature, end_feature - 1)]\n",
    "            \n",
    "            # Process each feature\n",
    "            for feature_idx in ranked_features[:config.max_features_to_analyze]:\n",
    "                try:\n",
    "                    feature_data = episode_df[episode_df['feature_index'] == feature_idx]\n",
    "                    \n",
    "                    if len(feature_data) == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    # Sort by activation value\n",
    "                    feature_data = feature_data.sort_values('activation', ascending=False)\n",
    "                    \n",
    "                    # Update global top examples\n",
    "                    for _, row in feature_data.head(config.top_k_global).iterrows():\n",
    "                        example = {\n",
    "                            'frame_idx': int(row['frame_index']),\n",
    "                            'episode_idx': int(row['episode_id']),\n",
    "                            'dataset_id': int(row['dataset_id']),\n",
    "                            'activation_value': float(row['activation'])\n",
    "                        }\n",
    "                        \n",
    "                        # Add to global high examples\n",
    "                        if len(top_examples[feature_idx]['global_high']) < config.top_k_global:\n",
    "                            top_examples[feature_idx]['global_high'].append(example)\n",
    "                        else:\n",
    "                            # Replace lowest if this is higher\n",
    "                            min_example = min(top_examples[feature_idx]['global_high'], \n",
    "                                            key=lambda x: x['activation_value'])\n",
    "                            if example['activation_value'] > min_example['activation_value']:\n",
    "                                top_examples[feature_idx]['global_high'].remove(min_example)\n",
    "                                top_examples[feature_idx]['global_high'].append(example)\n",
    "                    \n",
    "                    # Add per-episode examples\n",
    "                    episode_top = feature_data.head(config.top_s_per_episode)\n",
    "                    if dataset_id not in top_examples[feature_idx]['episode_examples']:\n",
    "                        top_examples[feature_idx]['episode_examples'][dataset_id] = {}\n",
    "                    if episode_id not in top_examples[feature_idx]['episode_examples'][dataset_id]:\n",
    "                        top_examples[feature_idx]['episode_examples'][dataset_id][episode_id] = []\n",
    "                    \n",
    "                    for _, row in episode_top.iterrows():\n",
    "                        example = {\n",
    "                            'frame_idx': int(row['frame_index']),\n",
    "                            'episode_idx': int(row['episode_id']),\n",
    "                            'dataset_id': int(row['dataset_id']),\n",
    "                            'activation_value': float(row['activation'])\n",
    "                        }\n",
    "                        top_examples[feature_idx]['episode_examples'][dataset_id][episode_id].append(example)\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error processing file {file_path}: {e}\")\n",
    "                    continue\n",
    "\n",
    "        # Force garbage collection after each batch\n",
    "        gc.collect()\n",
    "    \n",
    "    # Sort global examples\n",
    "    for feature_idx in ranked_features[:config.max_features_to_analyze]:\n",
    "        top_examples[feature_idx]['global_high'].sort(\n",
    "            key=lambda x: x['activation_value'], reverse=True\n",
    "        )\n",
    "    \n",
    "    return top_examples\n",
    "\n",
    "def save_batch_results(feature_stats: Dict[int, FeatureStatistics],\n",
    "                      ranked_features: List[int],\n",
    "                      top_examples: Dict[int, Dict[str, List]],\n",
    "                      batch_idx: int,\n",
    "                      config: AnalysisConfig):\n",
    "    \"\"\"Save results for a single batch\"\"\"\n",
    "    output_dir = Path(config.output_dir) / f\"batch_{batch_idx:02d}\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save feature statistics\n",
    "    stats_data = {\n",
    "        str(feature_idx): stats.to_dict()\n",
    "        for feature_idx, stats in feature_stats.items()\n",
    "    }\n",
    "\n",
    "    with open(output_dir / \"feature_statistics.json\", \"w\") as f:\n",
    "        json.dump(stats_data, f, indent=2)\n",
    "\n",
    "    # Save ranked features\n",
    "    ranking_data = {\n",
    "        'ranking_metric': config.ranking_metric,\n",
    "        'total_features': len(feature_stats),\n",
    "        'valid_features': len(ranked_features),\n",
    "        'ranked_features': ranked_features[:config.max_features_to_analyze]\n",
    "    }\n",
    "\n",
    "    with open(output_dir / \"feature_ranking.json\", \"w\") as f:\n",
    "        json.dump(ranking_data, f, indent=2)\n",
    "\n",
    "    # Save top examples\n",
    "    examples_dir = output_dir / \"examples\"\n",
    "    examples_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    for feature_idx in ranked_features[:]:\n",
    "        # Save global top examples\n",
    "        if feature_idx in top_examples:\n",
    "            feature_dir = examples_dir / f\"feature_{feature_idx:03d}\"\n",
    "            feature_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            with open(feature_dir / \"global_top_examples.json\", \"w\") as f:\n",
    "                json.dump(top_examples[feature_idx]['global_high'], f, indent=2)\n",
    "\n",
    "            # Convert episode_examples keys to regular Python integers\n",
    "            episode_examples = {}\n",
    "            for dataset_id, dataset_examples in top_examples[feature_idx]['episode_examples'].items():\n",
    "                episode_examples[int(dataset_id)] = {\n",
    "                    int(episode_id): examples \n",
    "                    for episode_id, examples in dataset_examples.items()\n",
    "                }\n",
    "\n",
    "            # Save per-episode examples\n",
    "            with open(feature_dir / \"episode_top_examples.json\", \"w\") as f:\n",
    "                json.dump(episode_examples, f, indent=2)\n",
    "\n",
    "    logging.info(f\"Batch {batch_idx} results saved to {output_dir}\")\n",
    "\n",
    "def process_all_features(parquet_dir: str, total_features: int, config: AnalysisConfig):\n",
    "    \"\"\"Process all features in batches\"\"\"\n",
    "    # Get feature batches\n",
    "    feature_batches = get_feature_batches(total_features)\n",
    "    \n",
    "    # Process each batch\n",
    "    for batch_idx, feature_batch in enumerate(feature_batches):\n",
    "        logging.info(f\"Processing batch {batch_idx + 1}/{len(feature_batches)}\")\n",
    "        \n",
    "        # Process features in this batch\n",
    "        feature_stats, ranked_features = process_feature_batch(parquet_dir, feature_batch, config)\n",
    "        \n",
    "        # Find top examples for this batch\n",
    "        top_examples = find_top_examples_for_batch(parquet_dir, feature_batch, ranked_features, config)\n",
    "        \n",
    "        # Save results for this batch\n",
    "        save_batch_results(feature_stats, ranked_features, top_examples, batch_idx, config)\n",
    "        \n",
    "        # Clear memory\n",
    "        del feature_stats\n",
    "        del ranked_features\n",
    "        del top_examples\n",
    "        import gc\n",
    "        gc.collect()\n",
    "\n",
    "def get_total_features_from_sample(parquet_dir: str) -> int:\n",
    "    \"\"\"Get the total number of features by reading a sample of parquet files\"\"\"\n",
    "    parquet_dir = Path(parquet_dir)\n",
    "    parquet_files = sorted(list(parquet_dir.glob(\"*.parquet\")))\n",
    "    \n",
    "    if not parquet_files:\n",
    "        raise ValueError(f\"No parquet files found in {parquet_dir}\")\n",
    "    \n",
    "    # Sample first few files to get feature range\n",
    "    max_feature = 0\n",
    "    for file_path in parquet_files[:10]:  # Check first 10 files\n",
    "        df = pd.read_parquet(file_path)\n",
    "        if len(df) > 0:\n",
    "            max_feature = max(max_feature, df['feature_index'].max())\n",
    "    \n",
    "    logging.info(f\"Detected maximum feature index: {max_feature}\")\n",
    "    return max_feature + 1  # Since features are 0-indexed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureStatistics:\n",
    "    \"\"\"Statistics for a single feature\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_idx: int):\n",
    "        self.feature_idx = feature_idx\n",
    "        self.values = []\n",
    "        self.frame_indices = []\n",
    "        self.episode_indices = []\n",
    "        self.dataset_indices = []\n",
    "        \n",
    "        # Computed statistics\n",
    "        self.mean = 0.0\n",
    "        self.std = 0.0\n",
    "        self.variance = 0.0\n",
    "        self.min_val = 0.0\n",
    "        self.max_val = 0.0\n",
    "        self.range_val = 0.0\n",
    "        self.range_75_95 = 0.0\n",
    "        self.percentiles = {}\n",
    "        self.sparsity = 0.0  # Fraction of values below threshold\n",
    "        self.activity_rate = 0.0  # Fraction of values above threshold\n",
    "        \n",
    "        # Rankings\n",
    "        self.variance_rank = 0\n",
    "        self.range_rank = 0\n",
    "        self.sparsity_rank = 0\n",
    "        self.composite_rank = 0\n",
    "    \n",
    "    def add_values(self, values: np.ndarray, frame_indices: List[int], episode_indices: List[int], dataset_indices: List[int]):\n",
    "        \"\"\"Add new values to the statistics\"\"\"\n",
    "        self.values.extend(values.tolist())\n",
    "        self.frame_indices.extend(frame_indices)\n",
    "        self.episode_indices.extend(episode_indices)\n",
    "        self.dataset_indices.extend(dataset_indices)\n",
    "    \n",
    "    def compute_statistics(self, sparsity_threshold: float = 0.1):\n",
    "        \"\"\"Compute final statistics from collected values\"\"\"\n",
    "        if not self.values:\n",
    "            return\n",
    "        \n",
    "        values_array = np.array(self.values)\n",
    "        \n",
    "        self.mean = float(values_array.mean())\n",
    "        self.std = float(values_array.std())\n",
    "        self.variance = float(values_array.var())\n",
    "        self.min_val = float(values_array.min())\n",
    "        self.max_val = float(values_array.max())\n",
    "        self.range_val = self.max_val - self.min_val\n",
    "        \n",
    "        # Percentiles\n",
    "        percentile_points = [1, 5, 10, 25, 50, 75, 90, 95, 99]\n",
    "        self.percentiles = {\n",
    "            p: float(np.percentile(values_array, p)) \n",
    "            for p in percentile_points\n",
    "        }\n",
    "        \n",
    "        self.range_75_95 = self.percentiles[95] - self.percentiles[75]\n",
    "        # Sparsity (fraction of values below threshold)\n",
    "        self.sparsity = float((np.abs(values_array) < sparsity_threshold).mean())\n",
    "        self.activity_rate = 1.0 - self.sparsity\n",
    "    \n",
    "    def get_ranking_score(self, metric: str) -> float:\n",
    "        \"\"\"Get score for ranking features\"\"\"\n",
    "        if metric == 'variance':\n",
    "            # return self.variance\n",
    "            return self.variance\n",
    "        elif metric == 'range':\n",
    "            return self.range_val\n",
    "        elif metric == 'sparsity':\n",
    "            # Higher activity rate (lower sparsity) is better\n",
    "            return self.activity_rate\n",
    "        elif metric == 'composite':\n",
    "            # Composite score: variance * range * activity_rate\n",
    "            return self.variance * self.range_val * self.activity_rate\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown ranking metric: {metric}\")\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary for saving\"\"\"\n",
    "        return {\n",
    "            'feature_idx': self.feature_idx,\n",
    "            'mean': self.mean,\n",
    "            'std': self.std,\n",
    "            'variance': self.variance,\n",
    "            'min': self.min_val,\n",
    "            'max': self.max_val,\n",
    "            'range': self.range_val,\n",
    "            'percentiles': self.percentiles,\n",
    "            'sparsity': self.sparsity,\n",
    "            'activity_rate': self.activity_rate,\n",
    "            'num_samples': len(self.values),\n",
    "            'rankings': {\n",
    "                'variance_rank': self.variance_rank,\n",
    "                'range_rank': self.range_rank,\n",
    "                'sparsity_rank': self.sparsity_rank,\n",
    "                'composite_rank': self.composite_rank\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Batch Processing Approach\n",
    "\n",
    "The batch processing approach splits the features into 20 smaller batches and processes each batch separately. This reduces memory usage significantly at the cost of reading through the parquet files multiple times.\n",
    "\n",
    "Key benefits:\n",
    "- **Memory efficient**: Only keeps statistics for ~5% of features in memory at any time\n",
    "- **Resumable**: Each batch is saved separately, so you can stop and resume\n",
    "- **Robust**: Less likely to crash due to memory issues\n",
    "\n",
    "The process works as follows:\n",
    "1. Split all features into 20 batches of roughly equal size\n",
    "2. For each batch, read through all parquet files but only process rows for features in that batch\n",
    "3. Compute statistics and find top examples for features in the current batch\n",
    "4. Save results for the batch and clear memory before moving to the next batch\n",
    "\n",
    "Results are saved in separate directories: `batch_00/`, `batch_01/`, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Analysis\n",
    "\n",
    "Now let's run the analysis on your parquet files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to your parquet files\n",
    "parquet_dir = \"../output/episode_activations\"\n",
    "\n",
    "# Auto-detect the total number of features from a sample of files\n",
    "total_features = get_total_features_from_sample(parquet_dir)\n",
    "\n",
    "# Process all features in batches\n",
    "process_all_features(parquet_dir, total_features, config)\n",
    "\n",
    "print(\"Batch processing complete! Results saved in separate batch directories.\")\n",
    "print(f\"Check the output directory: {config.output_dir}\")\n",
    "print(\"Each batch contains:\")\n",
    "print(\"  - feature_statistics.json: Statistics for features in that batch\")\n",
    "print(\"  - feature_ranking.json: Ranked features for that batch\")\n",
    "print(\"  - examples/: Top examples for each feature in that batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureStatistics:\n",
    "    \"\"\"Statistics for a single feature\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_idx: int):\n",
    "        self.feature_idx = feature_idx\n",
    "        self.values = []\n",
    "        self.frame_indices = []\n",
    "        self.episode_indices = []\n",
    "        self.dataset_indices = []\n",
    "        \n",
    "        # Computed statistics\n",
    "        self.mean = 0.0\n",
    "        self.std = 0.0\n",
    "        self.variance = 0.0\n",
    "        self.min_val = 0.0\n",
    "        self.max_val = 0.0\n",
    "        self.range_val = 0.0\n",
    "        self.range_75_95 = 0.0\n",
    "        self.percentiles = {}\n",
    "        self.sparsity = 0.0  # Fraction of values below threshold\n",
    "        self.activity_rate = 0.0  # Fraction of values above threshold\n",
    "        \n",
    "        # Rankings\n",
    "        self.variance_rank = 0\n",
    "        self.range_rank = 0\n",
    "        self.sparsity_rank = 0\n",
    "        self.composite_rank = 0\n",
    "    \n",
    "    def add_values(self, values: np.ndarray, frame_indices: List[int], episode_indices: List[int], dataset_indices: List[int]):\n",
    "        \"\"\"Add new values to the statistics\"\"\"\n",
    "        self.values.extend(values.tolist())\n",
    "        self.frame_indices.extend(frame_indices)\n",
    "        self.episode_indices.extend(episode_indices)\n",
    "        self.dataset_indices.extend(dataset_indices)\n",
    "    \n",
    "    def compute_statistics(self, sparsity_threshold: float = 0.1):\n",
    "        \"\"\"Compute final statistics from collected values\"\"\"\n",
    "        if not self.values:\n",
    "            return\n",
    "        \n",
    "        values_array = np.array(self.values)\n",
    "        \n",
    "        self.mean = float(values_array.mean())\n",
    "        self.std = float(values_array.std())\n",
    "        self.variance = float(values_array.var())\n",
    "        self.min_val = float(values_array.min())\n",
    "        self.max_val = float(values_array.max())\n",
    "        self.range_val = self.max_val - self.min_val\n",
    "        \n",
    "        # Percentiles\n",
    "        percentile_points = [1, 5, 10, 25, 50, 75, 90, 95, 99]\n",
    "        self.percentiles = {\n",
    "            p: float(np.percentile(values_array, p)) \n",
    "            for p in percentile_points\n",
    "        }\n",
    "        \n",
    "        self.range_75_95 = self.percentiles[95] - self.percentiles[75]\n",
    "        # Sparsity (fraction of values below threshold)\n",
    "        self.sparsity = float((np.abs(values_array) < sparsity_threshold).mean())\n",
    "        self.activity_rate = 1.0 - self.sparsity\n",
    "    \n",
    "    def get_ranking_score(self, metric: str) -> float:\n",
    "        \"\"\"Get score for ranking features\"\"\"\n",
    "        if metric == 'variance':\n",
    "            # return self.variance\n",
    "            return self.variance\n",
    "        elif metric == 'range':\n",
    "            return self.range_val\n",
    "        elif metric == 'sparsity':\n",
    "            # Higher activity rate (lower sparsity) is better\n",
    "            return self.activity_rate\n",
    "        elif metric == 'composite':\n",
    "            # Composite score: variance * range * activity_rate\n",
    "            return self.variance * self.range_val * self.activity_rate\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown ranking metric: {metric}\")\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary for saving\"\"\"\n",
    "        return {\n",
    "            'feature_idx': self.feature_idx,\n",
    "            'mean': self.mean,\n",
    "            'std': self.std,\n",
    "            'variance': self.variance,\n",
    "            'min': self.min_val,\n",
    "            'max': self.max_val,\n",
    "            'range': self.range_val,\n",
    "            'percentiles': self.percentiles,\n",
    "            'sparsity': self.sparsity,\n",
    "            'activity_rate': self.activity_rate,\n",
    "            'num_samples': len(self.values),\n",
    "            'rankings': {\n",
    "                'variance_rank': self.variance_rank,\n",
    "                'range_rank': self.range_rank,\n",
    "                'sparsity_rank': self.sparsity_rank,\n",
    "                'composite_rank': self.composite_rank\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureStatistics:\n",
    "    \"\"\"Statistics for a single feature\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_idx: int):\n",
    "        self.feature_idx = feature_idx\n",
    "        self.values = []\n",
    "        self.frame_indices = []\n",
    "        self.episode_indices = []\n",
    "        self.dataset_indices = []\n",
    "        \n",
    "        # Computed statistics\n",
    "        self.mean = 0.0\n",
    "        self.std = 0.0\n",
    "        self.variance = 0.0\n",
    "        self.min_val = 0.0\n",
    "        self.max_val = 0.0\n",
    "        self.range_val = 0.0\n",
    "        self.range_75_95 = 0.0\n",
    "        self.percentiles = {}\n",
    "        self.sparsity = 0.0  # Fraction of values below threshold\n",
    "        self.activity_rate = 0.0  # Fraction of values above threshold\n",
    "        \n",
    "        # Rankings\n",
    "        self.variance_rank = 0\n",
    "        self.range_rank = 0\n",
    "        self.sparsity_rank = 0\n",
    "        self.composite_rank = 0\n",
    "    \n",
    "    def add_values(self, values: np.ndarray, frame_indices: List[int], episode_indices: List[int], dataset_indices: List[int]):\n",
    "        \"\"\"Add new values to the statistics\"\"\"\n",
    "        self.values.extend(values.tolist())\n",
    "        self.frame_indices.extend(frame_indices)\n",
    "        self.episode_indices.extend(episode_indices)\n",
    "        self.dataset_indices.extend(dataset_indices)\n",
    "    \n",
    "    def compute_statistics(self, sparsity_threshold: float = 0.1):\n",
    "        \"\"\"Compute final statistics from collected values\"\"\"\n",
    "        if not self.values:\n",
    "            return\n",
    "        \n",
    "        values_array = np.array(self.values)\n",
    "        \n",
    "        self.mean = float(values_array.mean())\n",
    "        self.std = float(values_array.std())\n",
    "        self.variance = float(values_array.var())\n",
    "        self.min_val = float(values_array.min())\n",
    "        self.max_val = float(values_array.max())\n",
    "        self.range_val = self.max_val - self.min_val\n",
    "        \n",
    "        # Percentiles\n",
    "        percentile_points = [1, 5, 10, 25, 50, 75, 90, 95, 99]\n",
    "        self.percentiles = {\n",
    "            p: float(np.percentile(values_array, p)) \n",
    "            for p in percentile_points\n",
    "        }\n",
    "        \n",
    "        self.range_75_95 = self.percentiles[95] - self.percentiles[75]\n",
    "        # Sparsity (fraction of values below threshold)\n",
    "        self.sparsity = float((np.abs(values_array) < sparsity_threshold).mean())\n",
    "        self.activity_rate = 1.0 - self.sparsity\n",
    "    \n",
    "    def get_ranking_score(self, metric: str) -> float:\n",
    "        \"\"\"Get score for ranking features\"\"\"\n",
    "        if metric == 'variance':\n",
    "            # return self.variance\n",
    "            return self.variance\n",
    "        elif metric == 'range':\n",
    "            return self.range_val\n",
    "        elif metric == 'sparsity':\n",
    "            # Higher activity rate (lower sparsity) is better\n",
    "            return self.activity_rate\n",
    "        elif metric == 'composite':\n",
    "            # Composite score: variance * range * activity_rate\n",
    "            return self.variance * self.range_val * self.activity_rate\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown ranking metric: {metric}\")\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary for saving\"\"\"\n",
    "        return {\n",
    "            'feature_idx': self.feature_idx,\n",
    "            'mean': self.mean,\n",
    "            'std': self.std,\n",
    "            'variance': self.variance,\n",
    "            'min': self.min_val,\n",
    "            'max': self.max_val,\n",
    "            'range': self.range_val,\n",
    "            'percentiles': self.percentiles,\n",
    "            'sparsity': self.sparsity,\n",
    "            'activity_rate': self.activity_rate,\n",
    "            'num_samples': len(self.values),\n",
    "            'rankings': {\n",
    "                'variance_rank': self.variance_rank,\n",
    "                'range_rank': self.range_rank,\n",
    "                'sparsity_rank': self.sparsity_rank,\n",
    "                'composite_rank': self.composite_rank\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureStatistics:\n",
    "    \"\"\"Statistics for a single feature\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_idx: int):\n",
    "        self.feature_idx = feature_idx\n",
    "        self.values = []\n",
    "        self.frame_indices = []\n",
    "        self.episode_indices = []\n",
    "        self.dataset_indices = []\n",
    "        \n",
    "        # Computed statistics\n",
    "        self.mean = 0.0\n",
    "        self.std = 0.0\n",
    "        self.variance = 0.0\n",
    "        self.min_val = 0.0\n",
    "        self.max_val = 0.0\n",
    "        self.range_val = 0.0\n",
    "        self.range_75_95 = 0.0\n",
    "        self.percentiles = {}\n",
    "        self.sparsity = 0.0  # Fraction of values below threshold\n",
    "        self.activity_rate = 0.0  # Fraction of values above threshold\n",
    "        \n",
    "        # Rankings\n",
    "        self.variance_rank = 0\n",
    "        self.range_rank = 0\n",
    "        self.sparsity_rank = 0\n",
    "        self.composite_rank = 0\n",
    "    \n",
    "    def add_values(self, values: np.ndarray, frame_indices: List[int], episode_indices: List[int], dataset_indices: List[int]):\n",
    "        \"\"\"Add new values to the statistics\"\"\"\n",
    "        self.values.extend(values.tolist())\n",
    "        self.frame_indices.extend(frame_indices)\n",
    "        self.episode_indices.extend(episode_indices)\n",
    "        self.dataset_indices.extend(dataset_indices)\n",
    "    \n",
    "    def compute_statistics(self, sparsity_threshold: float = 0.1):\n",
    "        \"\"\"Compute final statistics from collected values\"\"\"\n",
    "        if not self.values:\n",
    "            return\n",
    "        \n",
    "        values_array = np.array(self.values)\n",
    "        \n",
    "        self.mean = float(values_array.mean())\n",
    "        self.std = float(values_array.std())\n",
    "        self.variance = float(values_array.var())\n",
    "        self.min_val = float(values_array.min())\n",
    "        self.max_val = float(values_array.max())\n",
    "        self.range_val = self.max_val - self.min_val\n",
    "        \n",
    "        # Percentiles\n",
    "        percentile_points = [1, 5, 10, 25, 50, 75, 90, 95, 99]\n",
    "        self.percentiles = {\n",
    "            p: float(np.percentile(values_array, p)) \n",
    "            for p in percentile_points\n",
    "        }\n",
    "        \n",
    "        self.range_75_95 = self.percentiles[95] - self.percentiles[75]\n",
    "        # Sparsity (fraction of values below threshold)\n",
    "        self.sparsity = float((np.abs(values_array) < sparsity_threshold).mean())\n",
    "        self.activity_rate = 1.0 - self.sparsity\n",
    "    \n",
    "    def get_ranking_score(self, metric: str) -> float:\n",
    "        \"\"\"Get score for ranking features\"\"\"\n",
    "        if metric == 'variance':\n",
    "            # return self.variance\n",
    "            return self.variance\n",
    "        elif metric == 'range':\n",
    "            return self.range_val\n",
    "        elif metric == 'sparsity':\n",
    "            # Higher activity rate (lower sparsity) is better\n",
    "            return self.activity_rate\n",
    "        elif metric == 'composite':\n",
    "            # Composite score: variance * range * activity_rate\n",
    "            return self.variance * self.range_val * self.activity_rate\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown ranking metric: {metric}\")\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary for saving\"\"\"\n",
    "        return {\n",
    "            'feature_idx': self.feature_idx,\n",
    "            'mean': self.mean,\n",
    "            'std': self.std,\n",
    "            'variance': self.variance,\n",
    "            'min': self.min_val,\n",
    "            'max': self.max_val,\n",
    "            'range': self.range_val,\n",
    "            'percentiles': self.percentiles,\n",
    "            'sparsity': self.sparsity,\n",
    "            'activity_rate': self.activity_rate,\n",
    "            'num_samples': len(self.values),\n",
    "            'rankings': {\n",
    "                'variance_rank': self.variance_rank,\n",
    "                'range_rank': self.range_rank,\n",
    "                'sparsity_rank': self.sparsity_rank,\n",
    "                'composite_rank': self.composite_rank\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureStatistics:\n",
    "    \"\"\"Statistics for a single feature\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_idx: int):\n",
    "        self.feature_idx = feature_idx\n",
    "        self.values = []\n",
    "        self.frame_indices = []\n",
    "        self.episode_indices = []\n",
    "        self.dataset_indices = []\n",
    "        \n",
    "        # Computed statistics\n",
    "        self.mean = 0.0\n",
    "        self.std = 0.0\n",
    "        self.variance = 0.0\n",
    "        self.min_val = 0.0\n",
    "        self.max_val = 0.0\n",
    "        self.range_val = 0.0\n",
    "        self.range_75_95 = 0.0\n",
    "        self.percentiles = {}\n",
    "        self.sparsity = 0.0  # Fraction of values below threshold\n",
    "        self.activity_rate = 0.0  # Fraction of values above threshold\n",
    "        \n",
    "        # Rankings\n",
    "        self.variance_rank = 0\n",
    "        self.range_rank = 0\n",
    "        self.sparsity_rank = 0\n",
    "        self.composite_rank = 0\n",
    "    \n",
    "    def add_values(self, values: np.ndarray, frame_indices: List[int], episode_indices: List[int], dataset_indices: List[int]):\n",
    "        \"\"\"Add new values to the statistics\"\"\"\n",
    "        self.values.extend(values.tolist())\n",
    "        self.frame_indices.extend(frame_indices)\n",
    "        self.episode_indices.extend(episode_indices)\n",
    "        self.dataset_indices.extend(dataset_indices)\n",
    "    \n",
    "    def compute_statistics(self, sparsity_threshold: float = 0.1):\n",
    "        \"\"\"Compute final statistics from collected values\"\"\"\n",
    "        if not self.values:\n",
    "            return\n",
    "        \n",
    "        values_array = np.array(self.values)\n",
    "        \n",
    "        self.mean = float(values_array.mean())\n",
    "        self.std = float(values_array.std())\n",
    "        self.variance = float(values_array.var())\n",
    "        self.min_val = float(values_array.min())\n",
    "        self.max_val = float(values_array.max())\n",
    "        self.range_val = self.max_val - self.min_val\n",
    "        \n",
    "        # Percentiles\n",
    "        percentile_points = [1, 5, 10, 25, 50, 75, 90, 95, 99]\n",
    "        self.percentiles = {\n",
    "            p: float(np.percentile(values_array, p)) \n",
    "            for p in percentile_points\n",
    "        }\n",
    "        \n",
    "        self.range_75_95 = self.percentiles[95] - self.percentiles[75]\n",
    "        # Sparsity (fraction of values below threshold)\n",
    "        self.sparsity = float((np.abs(values_array) < sparsity_threshold).mean())\n",
    "        self.activity_rate = 1.0 - self.sparsity\n",
    "    \n",
    "    def get_ranking_score(self, metric: str) -> float:\n",
    "        \"\"\"Get score for ranking features\"\"\"\n",
    "        if metric == 'variance':\n",
    "            # return self.variance\n",
    "            return self.variance\n",
    "        elif metric == 'range':\n",
    "            return self.range_val\n",
    "        elif metric == 'sparsity':\n",
    "            # Higher activity rate (lower sparsity) is better\n",
    "            return self.activity_rate\n",
    "        elif metric == 'composite':\n",
    "            # Composite score: variance * range * activity_rate\n",
    "            return self.variance * self.range_val * self.activity_rate\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown ranking metric: {metric}\")\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary for saving\"\"\"\n",
    "        return {\n",
    "            'feature_idx': self.feature_idx,\n",
    "            'mean': self.mean,\n",
    "            'std': self.std,\n",
    "            'variance': self.variance,\n",
    "            'min': self.min_val,\n",
    "            'max': self.max_val,\n",
    "            'range': self.range_val,\n",
    "            'percentiles': self.percentiles,\n",
    "            'sparsity': self.sparsity,\n",
    "            'activity_rate': self.activity_rate,\n",
    "            'num_samples': len(self.values),\n",
    "            'rankings': {\n",
    "                'variance_rank': self.variance_rank,\n",
    "                'range_rank': self.range_rank,\n",
    "                'sparsity_rank': self.sparsity_rank,\n",
    "                'composite_rank': self.composite_rank\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureStatistics:\n",
    "    \"\"\"Statistics for a single feature\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_idx: int):\n",
    "        self.feature_idx = feature_idx\n",
    "        self.values = []\n",
    "        self.frame_indices = []\n",
    "        self.episode_indices = []\n",
    "        self.dataset_indices = []\n",
    "        \n",
    "        # Computed statistics\n",
    "        self.mean = 0.0\n",
    "        self.std = 0.0\n",
    "        self.variance = 0.0\n",
    "        self.min_val = 0.0\n",
    "        self.max_val = 0.0\n",
    "        self.range_val = 0.0\n",
    "        self.range_75_95 = 0.0\n",
    "        self.percentiles = {}\n",
    "        self.sparsity = 0.0  # Fraction of values below threshold\n",
    "        self.activity_rate = 0.0  # Fraction of values above threshold\n",
    "        \n",
    "        # Rankings\n",
    "        self.variance_rank = 0\n",
    "        self.range_rank = 0\n",
    "        self.sparsity_rank = 0\n",
    "        self.composite_rank = 0\n",
    "    \n",
    "    def add_values(self, values: np.ndarray, frame_indices: List[int], episode_indices: List[int], dataset_indices: List[int]):\n",
    "        \"\"\"Add new values to the statistics\"\"\"\n",
    "        self.values.extend(values.tolist())\n",
    "        self.frame_indices.extend(frame_indices)\n",
    "        self.episode_indices.extend(episode_indices)\n",
    "        self.dataset_indices.extend(dataset_indices)\n",
    "    \n",
    "    def compute_statistics(self, sparsity_threshold: float = 0.1):\n",
    "        \"\"\"Compute final statistics from collected values\"\"\"\n",
    "        if not self.values:\n",
    "            return\n",
    "        \n",
    "        values_array = np.array(self.values)\n",
    "        \n",
    "        self.mean = float(values_array.mean())\n",
    "        self.std = float(values_array.std())\n",
    "        self.variance = float(values_array.var())\n",
    "        self.min_val = float(values_array.min())\n",
    "        self.max_val = float(values_array.max())\n",
    "        self.range_val = self.max_val - self.min_val\n",
    "        \n",
    "        # Percentiles\n",
    "        percentile_points = [1, 5, 10, 25, 50, 75, 90, 95, 99]\n",
    "        self.percentiles = {\n",
    "            p: float(np.percentile(values_array, p)) \n",
    "            for p in percentile_points\n",
    "        }\n",
    "        \n",
    "        self.range_75_95 = self.percentiles[95] - self.percentiles[75]\n",
    "        # Sparsity (fraction of values below threshold)\n",
    "        self.sparsity = float((np.abs(values_array) < sparsity_threshold).mean())\n",
    "        self.activity_rate = 1.0 - self.sparsity\n",
    "    \n",
    "    def get_ranking_score(self, metric: str) -> float:\n",
    "        \"\"\"Get score for ranking features\"\"\"\n",
    "        if metric == 'variance':\n",
    "            # return self.variance\n",
    "            return self.variance\n",
    "        elif metric == 'range':\n",
    "            return self.range_val\n",
    "        elif metric == 'sparsity':\n",
    "            # Higher activity rate (lower sparsity) is better\n",
    "            return self.activity_rate\n",
    "        elif metric == 'composite':\n",
    "            # Composite score: variance * range * activity_rate\n",
    "            return self.variance * self.range_val * self.activity_rate\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown ranking metric: {metric}\")\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary for saving\"\"\"\n",
    "        return {\n",
    "            'feature_idx': self.feature_idx,\n",
    "            'mean': self.mean,\n",
    "            'std': self.std,\n",
    "            'variance': self.variance,\n",
    "            'min': self.min_val,\n",
    "            'max': self.max_val,\n",
    "            'range': self.range_val,\n",
    "            'percentiles': self.percentiles,\n",
    "            'sparsity': self.sparsity,\n",
    "            'activity_rate': self.activity_rate,\n",
    "            'num_samples': len(self.values),\n",
    "            'rankings': {\n",
    "                'variance_rank': self.variance_rank,\n",
    "                'range_rank': self.range_rank,\n",
    "                'sparsity_rank': self.sparsity_rank,\n",
    "                'composite_rank': self.composite_rank\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureStatistics:\n",
    "    \"\"\"Statistics for a single feature\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_idx: int):\n",
    "        self.feature_idx = feature_idx\n",
    "        self.values = []\n",
    "        self.frame_indices = []\n",
    "        self.episode_indices = []\n",
    "        self.dataset_indices = []\n",
    "        \n",
    "        # Computed statistics\n",
    "        self.mean = 0.0\n",
    "        self.std = 0.0\n",
    "        self.variance = 0.0\n",
    "        self.min_val = 0.0\n",
    "        self.max_val = 0.0\n",
    "        self.range_val = 0.0\n",
    "        self.range_75_95 = 0.0\n",
    "        self.percentiles = {}\n",
    "        self.sparsity = 0.0  # Fraction of values below threshold\n",
    "        self.activity_rate = 0.0  # Fraction of values above threshold\n",
    "        \n",
    "        # Rankings\n",
    "        self.variance_rank = 0\n",
    "        self.range_rank = 0\n",
    "        self.sparsity_rank = 0\n",
    "        self.composite_rank = 0\n",
    "    \n",
    "    def add_values(self, values: np.ndarray, frame_indices: List[int], episode_indices: List[int], dataset_indices: List[int]):\n",
    "        \"\"\"Add new values to the statistics\"\"\"\n",
    "        self.values.extend(values.tolist())\n",
    "        self.frame_indices.extend(frame_indices)\n",
    "        self.episode_indices.extend(episode_indices)\n",
    "        self.dataset_indices.extend(dataset_indices)\n",
    "    \n",
    "    def compute_statistics(self, sparsity_threshold: float = 0.1):\n",
    "        \"\"\"Compute final statistics from collected values\"\"\"\n",
    "        if not self.values:\n",
    "            return\n",
    "        \n",
    "        values_array = np.array(self.values)\n",
    "        \n",
    "        self.mean = float(values_array.mean())\n",
    "        self.std = float(values_array.std())\n",
    "        self.variance = float(values_array.var())\n",
    "        self.min_val = float(values_array.min())\n",
    "        self.max_val = float(values_array.max())\n",
    "        self.range_val = self.max_val - self.min_val\n",
    "        \n",
    "        # Percentiles\n",
    "        percentile_points = [1, 5, 10, 25, 50, 75, 90, 95, 99]\n",
    "        self.percentiles = {\n",
    "            p: float(np.percentile(values_array, p)) \n",
    "            for p in percentile_points\n",
    "        }\n",
    "        \n",
    "        self.range_75_95 = self.percentiles[95] - self.percentiles[75]\n",
    "        # Sparsity (fraction of values below threshold)\n",
    "        self.sparsity = float((np.abs(values_array) < sparsity_threshold).mean())\n",
    "        self.activity_rate = 1.0 - self.sparsity\n",
    "    \n",
    "    def get_ranking_score(self, metric: str) -> float:\n",
    "        \"\"\"Get score for ranking features\"\"\"\n",
    "        if metric == 'variance':\n",
    "            # return self.variance\n",
    "            return self.variance\n",
    "        elif metric == 'range':\n",
    "            return self.range_val\n",
    "        elif metric == 'sparsity':\n",
    "            # Higher activity rate (lower sparsity) is better\n",
    "            return self.activity_rate\n",
    "        elif metric == 'composite':\n",
    "            # Composite score: variance * range * activity_rate\n",
    "            return self.variance * self.range_val * self.activity_rate\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown ranking metric: {metric}\")\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary for saving\"\"\"\n",
    "        return {\n",
    "            'feature_idx': self.feature_idx,\n",
    "            'mean': self.mean,\n",
    "            'std': self.std,\n",
    "            'variance': self.variance,\n",
    "            'min': self.min_val,\n",
    "            'max': self.max_val,\n",
    "            'range': self.range_val,\n",
    "            'percentiles': self.percentiles,\n",
    "            'sparsity': self.sparsity,\n",
    "            'activity_rate': self.activity_rate,\n",
    "            'num_samples': len(self.values),\n",
    "            'rankings': {\n",
    "                'variance_rank': self.variance_rank,\n",
    "                'range_rank': self.range_rank,\n",
    "                'sparsity_rank': self.sparsity_rank,\n",
    "                'composite_rank': self.composite_rank\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureStatistics:\n",
    "    \"\"\"Statistics for a single feature\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_idx: int):\n",
    "        self.feature_idx = feature_idx\n",
    "        self.values = []\n",
    "        self.frame_indices = []\n",
    "        self.episode_indices = []\n",
    "        self.dataset_indices = []\n",
    "        \n",
    "        # Computed statistics\n",
    "        self.mean = 0.0\n",
    "        self.std = 0.0\n",
    "        self.variance = 0.0\n",
    "        self.min_val = 0.0\n",
    "        self.max_val = 0.0\n",
    "        self.range_val = 0.0\n",
    "        self.range_75_95 = 0.0\n",
    "        self.percentiles = {}\n",
    "        self.sparsity = 0.0  # Fraction of values below threshold\n",
    "        self.activity_rate = 0.0  # Fraction of values above threshold\n",
    "        \n",
    "        # Rankings\n",
    "        self.variance_rank = 0\n",
    "        self.range_rank = 0\n",
    "        self.sparsity_rank = 0\n",
    "        self.composite_rank = 0\n",
    "    \n",
    "    def add_values(self, values: np.ndarray, frame_indices: List[int], episode_indices: List[int], dataset_indices: List[int]):\n",
    "        \"\"\"Add new values to the statistics\"\"\"\n",
    "        self.values.extend(values.tolist())\n",
    "        self.frame_indices.extend(frame_indices)\n",
    "        self.episode_indices.extend(episode_indices)\n",
    "        self.dataset_indices.extend(dataset_indices)\n",
    "    \n",
    "    def compute_statistics(self, sparsity_threshold: float = 0.1):\n",
    "        \"\"\"Compute final statistics from collected values\"\"\"\n",
    "        if not self.values:\n",
    "            return\n",
    "        \n",
    "        values_array = np.array(self.values)\n",
    "        \n",
    "        self.mean = float(values_array.mean())\n",
    "        self.std = float(values_array.std())\n",
    "        self.variance = float(values_array.var())\n",
    "        self.min_val = float(values_array.min())\n",
    "        self.max_val = float(values_array.max())\n",
    "        self.range_val = self.max_val - self.min_val\n",
    "        \n",
    "        # Percentiles\n",
    "        percentile_points = [1, 5, 10, 25, 50, 75, 90, 95, 99]\n",
    "        self.percentiles = {\n",
    "            p: float(np.percentile(values_array, p)) \n",
    "            for p in percentile_points\n",
    "        }\n",
    "        \n",
    "        self.range_75_95 = self.percentiles[95] - self.percentiles[75]\n",
    "        # Sparsity (fraction of values below threshold)\n",
    "        self.sparsity = float((np.abs(values_array) < sparsity_threshold).mean())\n",
    "        self.activity_rate = 1.0 - self.sparsity\n",
    "    \n",
    "    def get_ranking_score(self, metric: str) -> float:\n",
    "        \"\"\"Get score for ranking features\"\"\"\n",
    "        if metric == 'variance':\n",
    "            # return self.variance\n",
    "            return self.variance\n",
    "        elif metric == 'range':\n",
    "            return self.range_val\n",
    "        elif metric == 'sparsity':\n",
    "            # Higher activity rate (lower sparsity) is better\n",
    "            return self.activity_rate\n",
    "        elif metric == 'composite':\n",
    "            # Composite score: variance * range * activity_rate\n",
    "            return self.variance * self.range_val * self.activity_rate\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown ranking metric: {metric}\")\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary for saving\"\"\"\n",
    "        return {\n",
    "            'feature_idx': self.feature_idx,\n",
    "            'mean': self.mean,\n",
    "            'std': self.std,\n",
    "            'variance': self.variance,\n",
    "            'min': self.min_val,\n",
    "            'max': self.max_val,\n",
    "            'range': self.range_val,\n",
    "            'percentiles': self.percentiles,\n",
    "            'sparsity': self.sparsity,\n",
    "            'activity_rate': self.activity_rate,\n",
    "            'num_samples': len(self.values),\n",
    "            'rankings': {\n",
    "                'variance_rank': self.variance_rank,\n",
    "                'range_rank': self.range_rank,\n",
    "                'sparsity_rank': self.sparsity_rank,\n",
    "                'composite_rank': self.composite_rank\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureStatistics:\n",
    "    \"\"\"Statistics for a single feature\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_idx: int):\n",
    "        self.feature_idx = feature_idx\n",
    "        self.values = []\n",
    "        self.frame_indices = []\n",
    "        self.episode_indices = []\n",
    "        self.dataset_indices = []\n",
    "        \n",
    "        # Computed statistics\n",
    "        self.mean = 0.0\n",
    "        self.std = 0.0\n",
    "        self.variance = 0.0\n",
    "        self.min_val = 0.0\n",
    "        self.max_val = 0.0\n",
    "        self.range_val = 0.0\n",
    "        self.range_75_95 = 0.0\n",
    "        self.percentiles = {}\n",
    "        self.sparsity = 0.0  # Fraction of values below threshold\n",
    "        self.activity_rate = 0.0  # Fraction of values above threshold\n",
    "        \n",
    "        # Rankings\n",
    "        self.variance_rank = 0\n",
    "        self.range_rank = 0\n",
    "        self.sparsity_rank = 0\n",
    "        self.composite_rank = 0\n",
    "    \n",
    "    def add_values(self, values: np.ndarray, frame_indices: List[int], episode_indices: List[int], dataset_indices: List[int]):\n",
    "        \"\"\"Add new values to the statistics\"\"\"\n",
    "        self.values.extend(values.tolist())\n",
    "        self.frame_indices.extend(frame_indices)\n",
    "        self.episode_indices.extend(episode_indices)\n",
    "        self.dataset_indices.extend(dataset_indices)\n",
    "    \n",
    "    def compute_statistics(self, sparsity_threshold: float = 0.1):\n",
    "        \"\"\"Compute final statistics from collected values\"\"\"\n",
    "        if not self.values:\n",
    "            return\n",
    "        \n",
    "        values_array = np.array(self.values)\n",
    "        \n",
    "        self.mean = float(values_array.mean())\n",
    "        self.std = float(values_array.std())\n",
    "        self.variance = float(values_array.var())\n",
    "        self.min_val = float(values_array.min())\n",
    "        self.max_val = float(values_array.max())\n",
    "        self.range_val = self.max_val - self.min_val\n",
    "        \n",
    "        # Percentiles\n",
    "        percentile_points = [1, 5, 10, 25, 50, 75, 90, 95, 99]\n",
    "        self.percentiles = {\n",
    "            p: float(np.percentile(values_array, p)) \n",
    "            for p in percentile_points\n",
    "        }\n",
    "        \n",
    "        self.range_75_95 = self.percentiles[95] - self.percentiles[75]\n",
    "        # Sparsity (fraction of values below threshold)\n",
    "        self.sparsity = float((np.abs(values_array) < sparsity_threshold).mean())\n",
    "        self.activity_rate = 1.0 - self.sparsity\n",
    "    \n",
    "    def get_ranking_score(self, metric: str) -> float:\n",
    "        \"\"\"Get score for ranking features\"\"\"\n",
    "        if metric == 'variance':\n",
    "            # return self.variance\n",
    "            return self.variance\n",
    "        elif metric == 'range':\n",
    "            return self.range_val\n",
    "        elif metric == 'sparsity':\n",
    "            # Higher activity rate (lower sparsity) is better\n",
    "            return self.activity_rate\n",
    "        elif metric == 'composite':\n",
    "            # Composite score: variance * range * activity_rate\n",
    "            return self.variance * self.range_val * self.activity_rate\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown ranking metric: {metric}\")\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary for saving\"\"\"\n",
    "        return {\n",
    "            'feature_idx': self.feature_idx,\n",
    "            'mean': self.mean,\n",
    "            'std': self.std,\n",
    "            'variance': self.variance,\n",
    "            'min': self.min_val,\n",
    "            'max': self.max_val,\n",
    "            'range': self.range_val,\n",
    "            'percentiles': self.percentiles,\n",
    "            'sparsity': self.sparsity,\n",
    "            'activity_rate': self.activity_rate,\n",
    "            'num_samples': len(self.values),\n",
    "            'rankings': {\n",
    "                'variance_rank': self.variance_rank,\n",
    "                'range_rank': self.range_rank,\n",
    "                'sparsity_rank': self.sparsity_rank,\n",
    "                'composite_rank': self.composite_rank\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureStatistics:\n",
    "    \"\"\"Statistics for a single feature\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_idx: int):\n",
    "        self.feature_idx = feature_idx\n",
    "        self.values = []\n",
    "        self.frame_indices = []\n",
    "        self.episode_indices = []\n",
    "        self.dataset_indices = []\n",
    "        \n",
    "        # Computed statistics\n",
    "        self.mean = 0.0\n",
    "        self.std = 0.0\n",
    "        self.variance = 0.0\n",
    "        self.min_val = 0.0\n",
    "        self.max_val = 0.0\n",
    "        self.range_val = 0.0\n",
    "        self.range_75_95 = 0.0\n",
    "        self.percentiles = {}\n",
    "        self.sparsity = 0.0  # Fraction of values below threshold\n",
    "        self.activity_rate = 0.0  # Fraction of values above threshold\n",
    "        \n",
    "        # Rankings\n",
    "        self.variance_rank = 0\n",
    "        self.range_rank = 0\n",
    "        self.sparsity_rank = 0\n",
    "        self.composite_rank = 0\n",
    "    \n",
    "    def add_values(self, values: np.ndarray, frame_indices: List[int], episode_indices: List[int], dataset_indices: List[int]):\n",
    "        \"\"\"Add new values to the statistics\"\"\"\n",
    "        self.values.extend(values.tolist())\n",
    "        self.frame_indices.extend(frame_indices)\n",
    "        self.episode_indices.extend(episode_indices)\n",
    "        self.dataset_indices.extend(dataset_indices)\n",
    "    \n",
    "    def compute_statistics(self, sparsity_threshold: float = 0.1):\n",
    "        \"\"\"Compute final statistics from collected values\"\"\"\n",
    "        if not self.values:\n",
    "            return\n",
    "        \n",
    "        values_array = np.array(self.values)\n",
    "        \n",
    "        self.mean = float(values_array.mean())\n",
    "        self.std = float(values_array.std())\n",
    "        self.variance = float(values_array.var())\n",
    "        self.min_val = float(values_array.min())\n",
    "        self.max_val = float(values_array.max())\n",
    "        self.range_val = self.max_val - self.min_val\n",
    "        \n",
    "        # Percentiles\n",
    "        percentile_points = [1, 5, 10, 25, 50, 75, 90, 95, 99]\n",
    "        self.percentiles = {\n",
    "            p: float(np.percentile(values_array, p)) \n",
    "            for p in percentile_points\n",
    "        }\n",
    "        \n",
    "        self.range_75_95 = self.percentiles[95] - self.percentiles[75]\n",
    "        # Sparsity (fraction of values below threshold)\n",
    "        self.sparsity = float((np.abs(values_array) < sparsity_threshold).mean())\n",
    "        self.activity_rate = 1.0 - self.sparsity\n",
    "    \n",
    "    def get_ranking_score(self, metric: str) -> float:\n",
    "        \"\"\"Get score for ranking features\"\"\"\n",
    "        if metric == 'variance':\n",
    "            # return self.variance\n",
    "            return self.variance\n",
    "        elif metric == 'range':\n",
    "            return self.range_val\n",
    "        elif metric == 'sparsity':\n",
    "            # Higher activity rate (lower sparsity) is better\n",
    "            return self.activity_rate\n",
    "        elif metric == 'composite':\n",
    "            # Composite score: variance * range * activity_rate\n",
    "            return self.variance * self.range_val * self.activity_rate\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown ranking metric: {metric}\")\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary for saving\"\"\"\n",
    "        return {\n",
    "            'feature_idx': self.feature_idx,\n",
    "            'mean': self.mean,\n",
    "            'std': self.std,\n",
    "            'variance': self.variance,\n",
    "            'min': self.min_val,\n",
    "            'max': self.max_val,\n",
    "            'range': self.range_val,\n",
    "            'percentiles': self.percentiles,\n",
    "            'sparsity': self.sparsity,\n",
    "            'activity_rate': self.activity_rate,\n",
    "            'num_samples': len(self.values),\n",
    "            'rankings': {\n",
    "                'variance_rank': self.variance_rank,\n",
    "                'range_rank': self.range_rank,\n",
    "                'sparsity_rank': self.sparsity_rank,\n",
    "                'composite_rank': self.composite_rank\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureStatistics:\n",
    "    \"\"\"Statistics for a single feature\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_idx: int):\n",
    "        self.feature_idx = feature_idx\n",
    "        self.values = []\n",
    "        self.frame_indices = []\n",
    "        self.episode_indices = []\n",
    "        self.dataset_indices = []\n",
    "        \n",
    "        # Computed statistics\n",
    "        self.mean = 0.0\n",
    "        self.std = 0.0\n",
    "        self.variance = 0.0\n",
    "        self.min_val = 0.0\n",
    "        self.max_val = 0.0\n",
    "        self.range_val = 0.0\n",
    "        self.range_75_95 = 0.0\n",
    "        self.percentiles = {}\n",
    "        self.sparsity = 0.0  # Fraction of values below threshold\n",
    "        self.activity_rate = 0.0  # Fraction of values above threshold\n",
    "        \n",
    "        # Rankings\n",
    "        self.variance_rank = 0\n",
    "        self.range_rank = 0\n",
    "        self.sparsity_rank = 0\n",
    "        self.composite_rank = 0\n",
    "    \n",
    "    def add_values(self, values: np.ndarray, frame_indices: List[int], episode_indices: List[int], dataset_indices: List[int]):\n",
    "        \"\"\"Add new values to the statistics\"\"\"\n",
    "        self.values.extend(values.tolist())\n",
    "        self.frame_indices.extend(frame_indices)\n",
    "        self.episode_indices.extend(episode_indices)\n",
    "        self.dataset_indices.extend(dataset_indices)\n",
    "    \n",
    "    def compute_statistics(self, sparsity_threshold: float = 0.1):\n",
    "        \"\"\"Compute final statistics from collected values\"\"\"\n",
    "        if not self.values:\n",
    "            return\n",
    "        \n",
    "        values_array = np.array(self.values)\n",
    "        \n",
    "        self.mean = float(values_array.mean())\n",
    "        self.std = float(values_array.std())\n",
    "        self.variance = float(values_array.var())\n",
    "        self.min_val = float(values_array.min())\n",
    "        self.max_val = float(values_array.max())\n",
    "        self.range_val = self.max_val - self.min_val\n",
    "        \n",
    "        # Percentiles\n",
    "        percentile_points = [1, 5, 10, 25, 50, 75, 90, 95, 99]\n",
    "        self.percentiles = {\n",
    "            p: float(np.percentile(values_array, p)) \n",
    "            for p in percentile_points\n",
    "        }\n",
    "        \n",
    "        self.range_75_95 = self.percentiles[95] - self.percentiles[75]\n",
    "        # Sparsity (fraction of values below threshold)\n",
    "        self.sparsity = float((np.abs(values_array) < sparsity_threshold).mean())\n",
    "        self.activity_rate = 1.0 - self.sparsity\n",
    "    \n",
    "    def get_ranking_score(self, metric: str) -> float:\n",
    "        \"\"\"Get score for ranking features\"\"\"\n",
    "        if metric == 'variance':\n",
    "            # return self.variance\n",
    "            return self.variance\n",
    "        elif metric == 'range':\n",
    "            return self.range_val\n",
    "        elif metric == 'sparsity':\n",
    "            # Higher activity rate (lower sparsity) is better\n",
    "            return self.activity_rate\n",
    "        elif metric == 'composite':\n",
    "            # Composite score: variance * range * activity_rate\n",
    "            return self.variance * self.range_val * self.activity_rate\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown ranking metric: {metric}\")\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary for saving\"\"\"\n",
    "        return {\n",
    "            'feature_idx': self.feature_idx,\n",
    "            'mean': self.mean,\n",
    "            'std': self.std,\n",
    "            'variance': self.variance,\n",
    "            'min': self.min_val,\n",
    "            'max': self.max_val,\n",
    "            'range': self.range_val,\n",
    "            'percentiles': self.percentiles,\n",
    "            'sparsity': self.sparsity,\n",
    "            'activity_rate': self.activity_rate,\n",
    "            'num_samples': len(self.values),\n",
    "            'rankings': {\n",
    "                'variance_rank': self.variance_rank,\n",
    "                'range_rank': self.range_rank,\n",
    "                'sparsity_rank': self.sparsity_rank,\n",
    "                'composite_rank': self.composite_rank\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureStatistics:\n",
    "    \"\"\"Statistics for a single feature\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_idx: int):\n",
    "        self.feature_idx = feature_idx\n",
    "        self.values = []\n",
    "        self.frame_indices = []\n",
    "        self.episode_indices = []\n",
    "        self.dataset_indices = []\n",
    "        \n",
    "        # Computed statistics\n",
    "        self.mean = 0.0\n",
    "        self.std = 0.0\n",
    "        self.variance = 0.0\n",
    "        self.min_val = 0.0\n",
    "        self.max_val = 0.0\n",
    "        self.range_val = 0.0\n",
    "        self.range_75_95 = 0.0\n",
    "        self.percentiles = {}\n",
    "        self.sparsity = 0.0  # Fraction of values below threshold\n",
    "        self.activity_rate = 0.0  # Fraction of values above threshold\n",
    "        \n",
    "        # Rankings\n",
    "        self.variance_rank = 0\n",
    "        self.range_rank = 0\n",
    "        self.sparsity_rank = 0\n",
    "        self.composite_rank = 0\n",
    "    \n",
    "    def add_values(self, values: np.ndarray, frame_indices: List[int], episode_indices: List[int], dataset_indices: List[int]):\n",
    "        \"\"\"Add new values to the statistics\"\"\"\n",
    "        self.values.extend(values.tolist())\n",
    "        self.frame_indices.extend(frame_indices)\n",
    "        self.episode_indices.extend(episode_indices)\n",
    "        self.dataset_indices.extend(dataset_indices)\n",
    "    \n",
    "    def compute_statistics(self, sparsity_threshold: float = 0.1):\n",
    "        \"\"\"Compute final statistics from collected values\"\"\"\n",
    "        if not self.values:\n",
    "            return\n",
    "        \n",
    "        values_array = np.array(self.values)\n",
    "        \n",
    "        self.mean = float(values_array.mean())\n",
    "        self.std = float(values_array.std())\n",
    "        self.variance = float(values_array.var())\n",
    "        self.min_val = float(values_array.min())\n",
    "        self.max_val = float(values_array.max())\n",
    "        self.range_val = self.max_val - self.min_val\n",
    "        \n",
    "        # Percentiles\n",
    "        percentile_points = [1, 5, 10, 25, 50, 75, 90, 95, 99]\n",
    "        self.percentiles = {\n",
    "            p: float(np.percentile(values_array, p)) \n",
    "            for p in percentile_points\n",
    "        }\n",
    "        \n",
    "        self.range_75_95 = self.percentiles[95] - self.percentiles[75]\n",
    "        # Sparsity (fraction of values below threshold)\n",
    "        self.sparsity = float((np.abs(values_array) < sparsity_threshold).mean())\n",
    "        self.activity_rate = 1.0 - self.sparsity\n",
    "    \n",
    "    def get_ranking_score(self, metric: str) -> float:\n",
    "        \"\"\"Get score for ranking features\"\"\"\n",
    "        if metric == 'variance':\n",
    "            # return self.variance\n",
    "            return self.variance\n",
    "        elif metric == 'range':\n",
    "            return self.range_val\n",
    "        elif metric == 'sparsity':\n",
    "            # Higher activity rate (lower sparsity) is better\n",
    "            return self.activity_rate\n",
    "        elif metric == 'composite':\n",
    "            # Composite score: variance * range * activity_rate\n",
    "            return self.variance * self.range_val * self.activity_rate\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown ranking metric: {metric}\")\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary for saving\"\"\"\n",
    "        return {\n",
    "            'feature_idx': self.feature_idx,\n",
    "            'mean': self.mean,\n",
    "            'std': self.std,\n",
    "            'variance': self.variance,\n",
    "            'min': self.min_val,\n",
    "            'max': self.max_val,\n",
    "            'range': self.range_val,\n",
    "            'percentiles': self.percentiles,\n",
    "            'sparsity': self.sparsity,\n",
    "            'activity_rate': self.activity_rate,\n",
    "            'num_samples': len(self.values),\n",
    "            'rankings': {\n",
    "                'variance_rank': self.variance_rank,\n",
    "                'range_rank': self.range_rank,\n",
    "                'sparsity_rank': self.sparsity_rank,\n",
    "                'composite_rank': self.composite_rank\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureStatistics:\n",
    "    \"\"\"Statistics for a single feature\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_idx: int):\n",
    "        self.feature_idx = feature_idx\n",
    "        self.values = []\n",
    "        self.frame_indices = []\n",
    "        self.episode_indices = []\n",
    "        self.dataset_indices = []\n",
    "        \n",
    "        # Computed statistics\n",
    "        self.mean = 0.0\n",
    "        self.std = 0.0\n",
    "        self.variance = 0.0\n",
    "        self.min_val = 0.0\n",
    "        self.max_val = 0.0\n",
    "        self.range_val = 0.0\n",
    "        self.range_75_95 = 0.0\n",
    "        self.percentiles = {}\n",
    "        self.sparsity = 0.0  # Fraction of values below threshold\n",
    "        self.activity_rate = 0.0  # Fraction of values above threshold\n",
    "        \n",
    "        # Rankings\n",
    "        self.variance_rank = 0\n",
    "        self.range_rank = 0\n",
    "        self.sparsity_rank = 0\n",
    "        self.composite_rank = 0\n",
    "    \n",
    "    def add_values(self, values: np.ndarray, frame_indices: List[int], episode_indices: List[int], dataset_indices: List[int]):\n",
    "        \"\"\"Add new values to the statistics\"\"\"\n",
    "        self.values.extend(values.tolist())\n",
    "        self.frame_indices.extend(frame_indices)\n",
    "        self.episode_indices.extend(episode_indices)\n",
    "        self.dataset_indices.extend(dataset_indices)\n",
    "    \n",
    "    def compute_statistics(self, sparsity_threshold: float = 0.1):\n",
    "        \"\"\"Compute final statistics from collected values\"\"\"\n",
    "        if not self.values:\n",
    "            return\n",
    "        \n",
    "        values_array = np.array(self.values)\n",
    "        \n",
    "        self.mean = float(values_array.mean())\n",
    "        self.std = float(values_array.std())\n",
    "        self.variance = float(values_array.var())\n",
    "        self.min_val = float(values_array.min())\n",
    "        self.max_val = float(values_array.max())\n",
    "        self.range_val = self.max_val - self.min_val\n",
    "        \n",
    "        # Percentiles\n",
    "        percentile_points = [1, 5, 10, 25, 50, 75, 90, 95, 99]\n",
    "        self.percentiles = {\n",
    "            p: float(np.percentile(values_array, p)) \n",
    "            for p in percentile_points\n",
    "        }\n",
    "        \n",
    "        self.range_75_95 = self.percentiles[95] - self.percentiles[75]\n",
    "        # Sparsity (fraction of values below threshold)\n",
    "        self.sparsity = float((np.abs(values_array) < sparsity_threshold).mean())\n",
    "        self.activity_rate = 1.0 - self.sparsity\n",
    "    \n",
    "    def get_ranking_score(self, metric: str) -> float:\n",
    "        \"\"\"Get score for ranking features\"\"\"\n",
    "        if metric == 'variance':\n",
    "            # return self.variance\n",
    "            return self.variance\n",
    "        elif metric == 'range':\n",
    "            return self.range_val\n",
    "        elif metric == 'sparsity':\n",
    "            # Higher activity rate (lower sparsity) is better\n",
    "            return self.activity_rate\n",
    "        elif metric == 'composite':\n",
    "            # Composite score: variance * range * activity_rate\n",
    "            return self.variance * self.range_val * self.activity_rate\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown ranking metric: {metric}\")\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary for saving\"\"\"\n",
    "        return {\n",
    "            'feature_idx': self.feature_idx,\n",
    "            'mean': self.mean,\n",
    "            'std': self.std,\n",
    "            'variance': self.variance,\n",
    "            'min': self.min_val,\n",
    "            'max': self.max_val,\n",
    "            'range': self.range_val,\n",
    "            'percentiles': self.percentiles,\n",
    "            'sparsity': self.sparsity,\n",
    "            'activity_rate': self.activity_rate,\n",
    "            'num_samples': len(self.values),\n",
    "            'rankings': {\n",
    "                'variance_rank': self.variance_rank,\n",
    "                'range_rank': self.range_rank,\n",
    "                'sparsity_rank': self.sparsity_rank,\n",
    "                'composite_rank': self.composite_rank\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureStatistics:\n",
    "    \"\"\"Statistics for a single feature\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_idx: int):\n",
    "        self.feature_idx = feature_idx\n",
    "        self.values = []\n",
    "        self.frame_indices = []\n",
    "        self.episode_indices = []\n",
    "        self.dataset_indices = []\n",
    "        \n",
    "        # Computed statistics\n",
    "        self.mean = 0.0\n",
    "        self.std = 0.0\n",
    "        self.variance = 0.0\n",
    "        self.min_val = 0.0\n",
    "        self.max_val = 0.0\n",
    "        self.range_val = 0.0\n",
    "        self.range_75_95 = 0.0\n",
    "        self.percentiles = {}\n",
    "        self.sparsity = 0.0  # Fraction of values below threshold\n",
    "        self.activity_rate = 0.0  # Fraction of values above threshold\n",
    "        \n",
    "        # Rankings\n",
    "        self.variance_rank = 0\n",
    "        self.range_rank = 0\n",
    "        self.sparsity_rank = 0\n",
    "        self.composite_rank = 0\n",
    "    \n",
    "    def add_values(self, values: np.ndarray, frame_indices: List[int], episode_indices: List[int], dataset_indices: List[int]):\n",
    "        \"\"\"Add new values to the statistics\"\"\"\n",
    "        self.values.extend(values.tolist())\n",
    "        self.frame_indices.extend(frame_indices)\n",
    "        self.episode_indices.extend(episode_indices)\n",
    "        self.dataset_indices.extend(dataset_indices)\n",
    "    \n",
    "    def compute_statistics(self, sparsity_threshold: float = 0.1):\n",
    "        \"\"\"Compute final statistics from collected values\"\"\"\n",
    "        if not self.values:\n",
    "            return\n",
    "        \n",
    "        values_array = np.array(self.values)\n",
    "        \n",
    "        self.mean = float(values_array.mean())\n",
    "        self.std = float(values_array.std())\n",
    "        self.variance = float(values_array.var())\n",
    "        self.min_val = float(values_array.min())\n",
    "        self.max_val = float(values_array.max())\n",
    "        self.range_val = self.max_val - self.min_val\n",
    "        \n",
    "        # Percentiles\n",
    "        percentile_points = [1, 5, 10, 25, 50, 75, 90, 95, 99]\n",
    "        self.percentiles = {\n",
    "            p: float(np.percentile(values_array, p)) \n",
    "            for p in percentile_points\n",
    "        }\n",
    "        \n",
    "        self.range_75_95 = self.percentiles[95] - self.percentiles[75]\n",
    "        # Sparsity (fraction of values below threshold)\n",
    "        self.sparsity = float((np.abs(values_array) < sparsity_threshold).mean())\n",
    "        self.activity_rate = 1.0 - self.sparsity\n",
    "    \n",
    "    def get_ranking_score(self, metric: str) -> float:\n",
    "        \"\"\"Get score for ranking features\"\"\"\n",
    "        if metric == 'variance':\n",
    "            # return self.variance\n",
    "            return self.variance\n",
    "        elif metric == 'range':\n",
    "            return self.range_val\n",
    "        elif metric == 'sparsity':\n",
    "            # Higher activity rate (lower sparsity) is better\n",
    "            return self.activity_rate\n",
    "        elif metric == 'composite':\n",
    "            # Composite score: variance * range * activity_rate\n",
    "            return self.variance * self.range_val * self.activity_rate\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown ranking metric: {metric}\")\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary for saving\"\"\"\n",
    "        return {\n",
    "            'feature_idx': self.feature_idx,\n",
    "            'mean': self.mean,\n",
    "            'std': self.std,\n",
    "            'variance': self.variance,\n",
    "            'min': self.min_val,\n",
    "            'max': self.max_val,\n",
    "            'range': self.range_val,\n",
    "            'percentiles': self.percentiles,\n",
    "            'sparsity': self.sparsity,\n",
    "            'activity_rate': self.activity_rate,\n",
    "            'num_samples': len(self.values),\n",
    "            'rankings': {\n",
    "                'variance_rank': self.variance_rank,\n",
    "                'range_rank': self.range_rank,\n",
    "                'sparsity_rank': self.sparsity_rank,\n",
    "                'composite_rank': self.composite_rank\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureStatistics:\n",
    "    \"\"\"Statistics for a single feature\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_idx: int):\n",
    "        self.feature_idx = feature_idx\n",
    "        self.values = []\n",
    "        self.frame_indices = []\n",
    "        self.episode_indices = []\n",
    "        self.dataset_indices = []\n",
    "        \n",
    "        # Computed statistics\n",
    "        self.mean = 0.0\n",
    "        self.std = 0.0\n",
    "        self.variance = 0.0\n",
    "        self.min_val = 0.0\n",
    "        self.max_val = 0.0\n",
    "        self.range_val = 0.0\n",
    "        self.range_75_95 = 0.0\n",
    "        self.percentiles = {}\n",
    "        self.sparsity = 0.0  # Fraction of values below threshold\n",
    "        self.activity_rate = 0.0  # Fraction of values above threshold\n",
    "        \n",
    "        # Rankings\n",
    "        self.variance_rank = 0\n",
    "        self.range_rank = 0\n",
    "        self.sparsity_rank = 0\n",
    "        self.composite_rank = 0\n",
    "    \n",
    "    def add_values(self, values: np.ndarray, frame_indices: List[int], episode_indices: List[int], dataset_indices: List[int]):\n",
    "        \"\"\"Add new values to the statistics\"\"\"\n",
    "        self.values.extend(values.tolist())\n",
    "        self.frame_indices.extend(frame_indices)\n",
    "        self.episode_indices.extend(episode_indices)\n",
    "        self.dataset_indices.extend(dataset_indices)\n",
    "    \n",
    "    def compute_statistics(self, sparsity_threshold: float = 0.1):\n",
    "        \"\"\"Compute final statistics from collected values\"\"\"\n",
    "        if not self.values:\n",
    "            return\n",
    "        \n",
    "        values_array = np.array(self.values)\n",
    "        \n",
    "        self.mean = float(values_array.mean())\n",
    "        self.std = float(values_array.std())\n",
    "        self.variance = float(values_array.var())\n",
    "        self.min_val = float(values_array.min())\n",
    "        self.max_val = float(values_array.max())\n",
    "        self.range_val = self.max_val - self.min_val\n",
    "        \n",
    "        # Percentiles\n",
    "        percentile_points = [1, 5, 10, 25, 50, 75, 90, 95, 99]\n",
    "        self.percentiles = {\n",
    "            p: float(np.percentile(values_array, p)) \n",
    "            for p in percentile_points\n",
    "        }\n",
    "        \n",
    "        self.range_75_95 = self.percentiles[95] - self.percentiles[75]\n",
    "        # Sparsity (fraction of values below threshold)\n",
    "        self.sparsity = float((np.abs(values_array) < sparsity_threshold).mean())\n",
    "        self.activity_rate = 1.0 - self.sparsity\n",
    "    \n",
    "    def get_ranking_score(self, metric: str) -> float:\n",
    "        \"\"\"Get score for ranking features\"\"\"\n",
    "        if metric == 'variance':\n",
    "            # return self.variance\n",
    "            return self.variance\n",
    "        elif metric == 'range':\n",
    "            return self.range_val\n",
    "        elif metric == 'sparsity':\n",
    "            # Higher activity rate (lower sparsity) is better\n",
    "            return self.activity_rate\n",
    "        elif metric == 'composite':\n",
    "            # Composite score: variance * range * activity_rate\n",
    "            return self.variance * self.range_val * self.activity_rate\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown ranking metric: {metric}\")\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary for saving\"\"\"\n",
    "        return {\n",
    "            'feature_idx': self.feature_idx,\n",
    "            'mean': self.mean,\n",
    "            'std': self.std,\n",
    "            'variance': self.variance,\n",
    "            'min': self.min_val,\n",
    "            'max': self.max_val,\n",
    "            'range': self.range_val,\n",
    "            'percentiles': self.percentiles,\n",
    "            'sparsity': self.sparsity,\n",
    "            'activity_rate': self.activity_rate,\n",
    "            'num_samples': len(self.values),\n",
    "            'rankings': {\n",
    "                'variance_rank': self.variance_rank,\n",
    "                'range_rank': self.range_rank,\n",
    "                'sparsity_rank': self.sparsity_rank,\n",
    "                'composite_rank': self.composite_rank\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureStatistics:\n",
    "    \"\"\"Statistics for a single feature\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_idx: int):\n",
    "        self.feature_idx = feature_idx\n",
    "        self.values = []\n",
    "        self.frame_indices = []\n",
    "        self.episode_indices = []\n",
    "        self.dataset_indices = []\n",
    "        \n",
    "        # Computed statistics\n",
    "        self.mean = 0.0\n",
    "        self.std = 0.0\n",
    "        self.variance = 0.0\n",
    "        self.min_val = 0.0\n",
    "        self.max_val = 0.0\n",
    "        self.range_val = 0.0\n",
    "        self.range_75_95 = 0.0\n",
    "        self.percentiles = {}\n",
    "        self.sparsity = 0.0  # Fraction of values below threshold\n",
    "        self.activity_rate = 0.0  # Fraction of values above threshold\n",
    "        \n",
    "        # Rankings\n",
    "        self.variance_rank = 0\n",
    "        self.range_rank = 0\n",
    "        self.sparsity_rank = 0\n",
    "        self.composite_rank = 0\n",
    "    \n",
    "    def add_values(self, values: np.ndarray, frame_indices: List[int], episode_indices: List[int], dataset_indices: List[int]):\n",
    "        \"\"\"Add new values to the statistics\"\"\"\n",
    "        self.values.extend(values.tolist())\n",
    "        self.frame_indices.extend(frame_indices)\n",
    "        self.episode_indices.extend(episode_indices)\n",
    "        self.dataset_indices.extend(dataset_indices)\n",
    "    \n",
    "    def compute_statistics(self, sparsity_threshold: float = 0.1):\n",
    "        \"\"\"Compute final statistics from collected values\"\"\"\n",
    "        if not self.values:\n",
    "            return\n",
    "        \n",
    "        values_array = np.array(self.values)\n",
    "        \n",
    "        self.mean = float(values_array.mean())\n",
    "        self.std = float(values_array.std())\n",
    "        self.variance = float(values_array.var())\n",
    "        self.min_val = float(values_array.min())\n",
    "        self.max_val = float(values_array.max())\n",
    "        self.range_val = self.max_val - self.min_val\n",
    "        \n",
    "        # Percentiles\n",
    "        percentile_points = [1, 5, 10, 25, 50, 75, 90, 95, 99]\n",
    "        self.percentiles = {\n",
    "            p: float(np.percentile(values_array, p)) \n",
    "            for p in percentile_points\n",
    "        }\n",
    "        \n",
    "        self.range_75_95 = self.percentiles[95] - self.percentiles[75]\n",
    "        # Sparsity (fraction of values below threshold)\n",
    "        self.sparsity = float((np.abs(values_array) < sparsity_threshold).mean())\n",
    "        self.activity_rate = 1.0 - self.sparsity\n",
    "    \n",
    "    def get_ranking_score(self, metric: str) -> float:\n",
    "        \"\"\"Get score for ranking features\"\"\"\n",
    "        if metric == 'variance':\n",
    "            # return self.variance\n",
    "            return self.variance\n",
    "        elif metric == 'range':\n",
    "            return self.range_val\n",
    "        elif metric == 'sparsity':\n",
    "            # Higher activity rate (lower sparsity) is better\n",
    "            return self.activity_rate\n",
    "        elif metric == 'composite':\n",
    "            # Composite score: variance * range * activity_rate\n",
    "            return self.variance * self.range_val * self.activity_rate\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown ranking metric: {metric}\")\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary for saving\"\"\"\n",
    "        return {\n",
    "            'feature_idx': self.feature_idx,\n",
    "            'mean': self.mean,\n",
    "            'std': self.std,\n",
    "            'variance': self.variance,\n",
    "            'min': self.min_val,\n",
    "            'max': self.max_val,\n",
    "            'range': self.range_val,\n",
    "            'percentiles': self.percentiles,\n",
    "            'sparsity': self.sparsity,\n",
    "            'activity_rate': self.activity_rate,\n",
    "            'num_samples': len(self.values),\n",
    "            'rankings': {\n",
    "                'variance_rank': self.variance_rank,\n",
    "                'range_rank': self.range_rank,\n",
    "                'sparsity_rank': self.sparsity_rank,\n",
    "                'composite_rank': self.composite_rank\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureStatistics:\n",
    "    \"\"\"Statistics for a single feature\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_idx: int):\n",
    "        self.feature_idx = feature_idx\n",
    "        self.values = []\n",
    "        self.frame_indices = []\n",
    "        self.episode_indices = []\n",
    "        self.dataset_indices = []\n",
    "        \n",
    "        # Computed statistics\n",
    "        self.mean = 0.0\n",
    "        self.std = 0.0\n",
    "        self.variance = 0.0\n",
    "        self.min_val = 0.0\n",
    "        self.max_val = 0.0\n",
    "        self.range_val = 0.0\n",
    "        self.range_75_95 = 0.0\n",
    "        self.percentiles = {}\n",
    "        self.sparsity = 0.0  # Fraction of values below threshold\n",
    "        self.activity_rate = 0.0  # Fraction of values above threshold\n",
    "        \n",
    "        # Rankings\n",
    "        self.variance_rank = 0\n",
    "        self.range_rank = 0\n",
    "        self.sparsity_rank = 0\n",
    "        self.composite_rank = 0\n",
    "    \n",
    "    def add_values(self, values: np.ndarray, frame_indices: List[int], episode_indices: List[int], dataset_indices: List[int]):\n",
    "        \"\"\"Add new values to the statistics\"\"\"\n",
    "        self.values.extend(values.tolist())\n",
    "        self.frame_indices.extend(frame_indices)\n",
    "        self.episode_indices.extend(episode_indices)\n",
    "        self.dataset_indices.extend(dataset_indices)\n",
    "    \n",
    "    def compute_statistics(self, sparsity_threshold: float = 0.1):\n",
    "        \"\"\"Compute final statistics from collected values\"\"\"\n",
    "        if not self.values:\n",
    "            return\n",
    "        \n",
    "        values_array = np.array(self.values)\n",
    "        \n",
    "        self.mean = float(values_array.mean())\n",
    "        self.std = float(values_array.std())\n",
    "        self.variance = float(values_array.var())\n",
    "        self.min_val = float(values_array.min())\n",
    "        self.max_val = float(values_array.max())\n",
    "        self.range_val = self.max_val - self.min_val\n",
    "        \n",
    "        # Percentiles\n",
    "        percentile_points = [1, 5, 10, 25, 50, 75, 90, 95, 99]\n",
    "        self.percentiles = {\n",
    "            p: float(np.percentile(values_array, p)) \n",
    "            for p in percentile_points\n",
    "        }\n",
    "        \n",
    "        self.range_75_95 = self.percentiles[95] - self.percentiles[75]\n",
    "        # Sparsity (fraction of values below threshold)\n",
    "        self.sparsity = float((np.abs(values_array) < sparsity_threshold).mean())\n",
    "        self.activity_rate = 1.0 - self.sparsity\n",
    "    \n",
    "    def get_ranking_score(self, metric: str) -> float:\n",
    "        \"\"\"Get score for ranking features\"\"\"\n",
    "        if metric == 'variance':\n",
    "            # return self.variance\n",
    "            return self.variance\n",
    "        elif metric == 'range':\n",
    "            return self.range_val\n",
    "        elif metric == 'sparsity':\n",
    "            # Higher activity rate (lower sparsity) is better\n",
    "            return self.activity_rate\n",
    "        elif metric == 'composite':\n",
    "            # Composite score: variance * range * activity_rate\n",
    "            return self.variance * self.range_val * self.activity_rate\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown ranking metric: {metric}\")\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary for saving\"\"\"\n",
    "        return {\n",
    "            'feature_idx': self.feature_idx,\n",
    "            'mean': self.mean,\n",
    "            'std': self.std,\n",
    "            'variance': self.variance,\n",
    "            'min': self.min_val,\n",
    "            'max': self.max_val,\n",
    "            'range': self.range_val,\n",
    "            'percentiles': self.percentiles,\n",
    "            'sparsity': self.sparsity,\n",
    "            'activity_rate': self.activity_rate,\n",
    "            'num_samples': len(self.values),\n",
    "            'rankings': {\n",
    "                'variance_rank': self.variance_rank,\n",
    "                'range_rank': self.range_rank,\n",
    "                'sparsity_rank': self.sparsity_rank,\n",
    "                'composite_rank': self.composite_rank\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Working with Batch Results\n",
    "\n",
    "Once the batch processing is complete, you can use the following utilities to work with the results:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_batch_results(output_dir: str) -> Tuple[Dict[int, FeatureStatistics], List[int]]:\n",
    "    \"\"\"Load and combine results from all batches\"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    all_feature_stats = {}\n",
    "    \n",
    "    # Find all batch directories\n",
    "    batch_dirs = sorted([d for d in output_dir.iterdir() if d.is_dir() and d.name.startswith('batch_')])\n",
    "    \n",
    "    for batch_dir in batch_dirs:\n",
    "        stats_file = batch_dir / \"feature_statistics.json\"\n",
    "        if stats_file.exists():\n",
    "            with open(stats_file, 'r') as f:\n",
    "                batch_stats = json.load(f)\n",
    "            \n",
    "            # Convert back to FeatureStatistics objects\n",
    "            for feature_idx_str, stats_dict in batch_stats.items():\n",
    "                feature_idx = int(feature_idx_str)\n",
    "                feature_stats = FeatureStatistics(feature_idx)\n",
    "                \n",
    "                # Set the computed statistics\n",
    "                feature_stats.mean = stats_dict['mean']\n",
    "                feature_stats.std = stats_dict['std']\n",
    "                feature_stats.variance = stats_dict['variance']\n",
    "                feature_stats.min_val = stats_dict['min']\n",
    "                feature_stats.max_val = stats_dict['max']\n",
    "                feature_stats.range_val = stats_dict['range']\n",
    "                feature_stats.percentiles = stats_dict['percentiles']\n",
    "                feature_stats.sparsity = stats_dict['sparsity']\n",
    "                feature_stats.activity_rate = stats_dict['activity_rate']\n",
    "                \n",
    "                all_feature_stats[feature_idx] = feature_stats\n",
    "    \n",
    "    # Rank all features together\n",
    "    ranked_features = rank_features(all_feature_stats, config)\n",
    "    \n",
    "    return all_feature_stats, ranked_features\n",
    "\n",
    "def get_top_features_across_batches(output_dir: str, top_k: int = 50) -> List[int]:\n",
    "    \"\"\"Get the top K features across all batches\"\"\"\n",
    "    all_feature_stats, ranked_features = load_all_batch_results(output_dir)\n",
    "    return ranked_features[:top_k]\n",
    "\n",
    "def print_top_features(output_dir: str, top_k: int = 10):\n",
    "    \"\"\"Print information about top features\"\"\"\n",
    "    all_feature_stats, ranked_features = load_all_batch_results(output_dir)\n",
    "    \n",
    "    print(f\"Top {top_k} Features Across All Batches:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for i, feature_idx in enumerate(ranked_features[:top_k]):\n",
    "        stats = all_feature_stats[feature_idx]\n",
    "        print(f\"{i+1:2d}. Feature {feature_idx:4d}:\")\n",
    "        print(f\"    Range (75-95%): {stats.range_75_95:.4f}\")\n",
    "        print(f\"    Variance:       {stats.variance:.4f}\")\n",
    "        print(f\"    Range:          {stats.range_val:.3f}\")\n",
    "        print(f\"    Activity Rate:  {stats.activity_rate:.3f}\")\n",
    "        print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_batch_results(output_dir: str, top_k_features: int = 100):\n",
    "    \"\"\"Consolidate results from all batches into a single summary\"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    \n",
    "    # Load all results\n",
    "    all_feature_stats, ranked_features = load_all_batch_results(output_dir)\n",
    "    \n",
    "    # Create consolidated directory\n",
    "    consolidated_dir = output_dir / \"consolidated\"\n",
    "    consolidated_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Save consolidated feature statistics for top features\n",
    "    top_features = ranked_features[:top_k_features]\n",
    "    consolidated_stats = {\n",
    "        str(feature_idx): all_feature_stats[feature_idx].to_dict()\n",
    "        for feature_idx in top_features\n",
    "    }\n",
    "    \n",
    "    with open(consolidated_dir / \"top_feature_statistics.json\", \"w\") as f:\n",
    "        json.dump(consolidated_stats, f, indent=2)\n",
    "    \n",
    "    # Save consolidated ranking\n",
    "    ranking_data = {\n",
    "        'ranking_metric': config.ranking_metric,\n",
    "        'total_features_analyzed': len(all_feature_stats),\n",
    "        'top_features_consolidated': top_k_features,\n",
    "        'ranked_features': top_features\n",
    "    }\n",
    "    \n",
    "    with open(consolidated_dir / \"consolidated_ranking.json\", \"w\") as f:\n",
    "        json.dump(ranking_data, f, indent=2)\n",
    "    \n",
    "    # Collect top examples from batches for top features\n",
    "    consolidated_examples = {}\n",
    "    for feature_idx in top_features:\n",
    "        # Find which batch this feature belongs to\n",
    "        for batch_dir in sorted([d for d in output_dir.iterdir() if d.is_dir() and d.name.startswith('batch_')]):\n",
    "            examples_file = batch_dir / \"examples\" / f\"feature_{feature_idx:03d}\" / \"global_top_examples.json\"\n",
    "            if examples_file.exists():\n",
    "                with open(examples_file, 'r') as f:\n",
    "                    examples = json.load(f)\n",
    "                consolidated_examples[feature_idx] = examples\n",
    "                break\n",
    "    \n",
    "    # Save consolidated examples\n",
    "    with open(consolidated_dir / \"top_feature_examples.json\", \"w\") as f:\n",
    "        json.dump(consolidated_examples, f, indent=2)\n",
    "    \n",
    "    logging.info(f\"Consolidated results saved to {consolidated_dir}\")\n",
    "    logging.info(f\"Top {top_k_features} features consolidated\")\n",
    "    \n",
    "    return top_features\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdt-lerobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
